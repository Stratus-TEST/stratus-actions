diff --git a/.github/dependabot.yml b/.github/dependabot.yml
new file mode 100644
index 0000000..83a482f
--- /dev/null
+++ b/.github/dependabot.yml
@@ -0,0 +1,32 @@
+# To get started with Dependabot version updates, you'll need to specify which
+# package ecosystems to update and where the package manifests are located.
+# Please see the documentation for all configuration options:
+# https://docs.github.com/code-security/dependabot/dependabot-version-updates/configuration-options-for-the-dependabot.yml-file
+
+version: 2
+updates:
+  - package-ecosystem: "github-actions"
+    directory: ".github/workflows"
+    schedule:
+      interval: "daily"
+    groups:
+      all-dependencies:
+        patterns: ["*"]
+    auto-merge: true
+  # NOTE: We use pip/requirements.txt for Dependabot support. Keep requirements.txt and pyproject.toml in sync manually.
+  - package-ecosystem: "pip"
+    directory: "/build-scope-analyzer"
+    schedule:
+      interval: "daily"
+    groups:
+      all-dependencies:
+        patterns: ["*"]
+    auto-merge: true
+  - package-ecosystem: "docker"
+    directory: "/build-scope-analyzer"
+    schedule:
+      interval: "daily"
+    groups:
+      all-dependencies:
+        patterns: ["*"]
+    auto-merge: true
diff --git a/.github/release.yml b/.github/release.yml
new file mode 100644
index 0000000..a39ae55
--- /dev/null
+++ b/.github/release.yml
@@ -0,0 +1,32 @@
+# GitHub Release Configuration
+# This file configures how GitHub auto-generates release notes
+# 
+# IMPORTANT: This file ONLY controls release notes categorization
+# It does NOT determine version numbers (major/minor/patch)
+# Version bumping is handled by the workflow logic based on PR labels
+
+changelog:
+  exclude:
+    labels:
+      - ignore-for-release
+    authors:
+      - dependabot
+  categories:
+    - title: üöÄ Features
+      labels:
+        - enhancement
+        - feature
+    - title: üêõ Bug Fixes
+      labels:
+        - bug
+        - bugfix
+    - title: üìö Documentation
+      labels:
+        - documentation
+    - title: üîß Maintenance
+      labels:
+        - maintenance
+        - chore
+    - title: ‚ö†Ô∏è Breaking Changes
+      labels:
+        - breaking-change
\ No newline at end of file
diff --git a/.github/workflows/pre-merge-version.yml b/.github/workflows/pre-merge-version.yml
new file mode 100644
index 0000000..91c9b1c
--- /dev/null
+++ b/.github/workflows/pre-merge-version.yml
@@ -0,0 +1,219 @@
+name: Pre-Merge Version Check
+
+on:
+  pull_request:
+    types: [opened, synchronize, labeled]
+
+permissions:
+  contents: write
+  pull-requests: write
+
+jobs:
+  pre-merge-version:
+    name: Check Next Semantic Version
+    runs-on: ubuntu-latest
+    if: github.repository == 'stratus-test/stratus-actions'
+    steps:
+      - uses: actions/checkout@v4
+        with:
+          fetch-depth: 0
+
+      - name: Check if last commit was made by the app
+        id: skip
+        run: |
+          # Get the latest commit SHA on the PR branch
+          COMMIT_SHA="${{ github.event.pull_request.head.sha }}"
+          # Get the author login using the GitHub API
+          AUTHOR_LOGIN=$(gh api repos/${{ github.repository }}/commits/$COMMIT_SHA --jq '.author.login')
+          echo "Author login: $AUTHOR_LOGIN"
+          # Replace 'stratus-ga-bot-stratus-test[bot]' with your app's bot login
+          if [[ "$AUTHOR_LOGIN" == "stratus-ga-bot-stratus-test[bot]" ]]; then
+            echo "skip=true" >> $GITHUB_OUTPUT
+          else
+            echo "skip=false" >> $GITHUB_OUTPUT
+          fi
+        env:
+          GH_TOKEN: ${{ github.token }}
+
+      - name: Preview Next Version
+        if: steps.skip.outputs.skip != 'true'
+        id: version
+        uses: ./release
+        with:
+          dry-run: true
+      - name: Comment Next Version on PR
+        if: github.event_name == 'pull_request' && steps.skip.outputs.skip != 'true'
+        uses: actions/github-script@v7
+        with:
+          script: |
+            const version = process.env.VERSION || '${{ steps.version.outputs.new_version }}';
+            const body = `üî¢ If merged now, the next release version will be: **${version}**\n\nThe action.yml and pyproject.toml have been updated in this PR branch.`;
+            await github.rest.issues.createComment({
+              owner: context.repo.owner,
+              repo: context.repo.repo,
+              issue_number: context.issue.number,
+              body
+            });
+      - name: Update all action.yml, action.yaml, and pyproject.toml files with next version
+        id: update-files
+        if: steps.skip.outputs.skip != 'true'
+        run: |
+          VERSION=${{ steps.version.outputs.new_version }}
+          VERSION_NO_V=${VERSION#v}
+          MAJOR_TAG=v${VERSION_NO_V%%.*}
+          # Update all action.yml and action.yaml image tags (handle both : and @ before version)
+          find . -type f \( -name action.yml -o -name action.yaml \) | while read f; do
+            sed -i -E "s|image: \"docker://ghcr.io/.*/stratus-actions/.+[:@][^\"]*\"|image: \"docker://ghcr.io/${{ github.repository }}/$(basename $(dirname $f)):${VERSION}\"|" "$f"
+          done
+          # Update all pyproject.toml version fields
+          find . -type f -name pyproject.toml | while read f; do
+            sed -i "s/^version = \".*\"/version = \"${VERSION_NO_V}\"/" "$f"
+          done
+          # Update all .md files to reference the latest major tag (e.g., @v1)
+          find . -type f -name "*.md" | while read f; do
+            sed -i -E "s|(stratus-actions/[a-zA-Z0-9_-]+)@[^\s'\"]+|\1@${MAJOR_TAG}|g" "$f"
+          done
+          echo "Show updated files:"
+          git status --porcelain
+          if git status --porcelain | grep .; then
+            echo "changed=true" >> $GITHUB_OUTPUT
+          else
+            echo "changed=false" >> $GITHUB_OUTPUT
+          fi
+      - name: Create GitHub App JWT and Installation Access Token
+        if: steps.update-files.outputs.changed == 'true' && steps.skip.outputs.skip != 'true'
+        id: jwt
+        env:
+          STRATUS_GA_BOT_PEM: ${{ secrets.STRATUS_GA_BOT_PEM }}
+          STRATUS_GA_BOT_ID: ${{ vars.STRATUS_GA_BOT_ID }}
+          GITHUB_REPOSITORY: ${{ github.repository }}
+          GITHUB_HEAD_REF: ${{ github.head_ref }}
+        run: |
+          # Install jq and openssl if not present
+          sudo apt-get update && sudo apt-get install -y jq
+
+          # Write PEM to file
+          echo "$STRATUS_GA_BOT_PEM" > private-key.pem
+
+          # Generate JWT
+          now=$(date +%s)
+          exp=$((now + 540))
+          header='{"alg":"RS256","typ":"JWT"}'
+          payload="{\"iat\":$now,\"exp\":$exp,\"iss\":\"$STRATUS_GA_BOT_ID\"}"
+          base64url() { openssl base64 -e -A | tr '+/' '-_' | tr -d '='; }
+          header_b64=$(echo -n "$header" | base64url)
+          payload_b64=$(echo -n "$payload" | base64url)
+          unsigned_token="$header_b64.$payload_b64"
+          signature=$(echo -n "$unsigned_token" | openssl dgst -sha256 -sign private-key.pem | base64url)
+          jwt="$unsigned_token.$signature"
+
+          # Get installation ID
+          installation_id=$(curl -s -H "Authorization: Bearer $jwt" -H "Accept: application/vnd.github+json" \
+            https://api.github.com/repos/$GITHUB_REPOSITORY/installation | jq -r .id)
+
+          # Get installation access token
+          access_token=$(curl -s -X POST -H "Authorization: Bearer $jwt" -H "Accept: application/vnd.github+json" \
+            https://api.github.com/app/installations/$installation_id/access_tokens | jq -r .token)
+
+          echo "strauts_ga_bot_installation_token=$access_token" >> $GITHUB_OUTPUT
+
+          rm private-key.pem
+      - name: Commit and push version bump via API
+        if: steps.update-files.outputs.changed == 'true' && steps.skip.outputs.skip != 'true'
+        uses: actions/github-script@v7
+        with:
+          github-token: ${{ steps.jwt.outputs.strauts_ga_bot_installation_token }}
+          script: |
+            const fs = require('fs');
+            const path = require('path');
+
+            // Get current branch info
+            const branch = context.payload.pull_request.head.ref;
+            const owner = context.repo.owner;
+            const repo = context.repo.repo;
+            const version = '${{ steps.version.outputs.new_version }}';
+
+            console.log(`Updating files on branch: ${branch}`);
+
+            try {
+              // Get current commit SHA of the branch
+              const branchRef = await github.rest.git.getRef({
+                owner,
+                repo,
+                ref: `heads/${branch}`
+              });
+
+              const currentCommitSha = branchRef.data.object.sha;
+
+              // Get current tree
+              const currentCommit = await github.rest.git.getCommit({
+                owner,
+                repo,
+                commit_sha: currentCommitSha
+              });
+
+              // Read updated files
+              const actionYmlContent = fs.readFileSync('build-scope-analyzer/action.yml', 'utf8');
+              const pyprojectTomlContent = fs.readFileSync('build-scope-analyzer/pyproject.toml', 'utf8');
+
+              // Create blobs for the updated files
+              const actionYmlBlob = await github.rest.git.createBlob({
+                owner,
+                repo,
+                content: Buffer.from(actionYmlContent).toString('base64'),
+                encoding: 'base64'
+              });
+
+              const pyprojectTomlBlob = await github.rest.git.createBlob({
+                owner,
+                repo,
+                content: Buffer.from(pyprojectTomlContent).toString('base64'),
+                encoding: 'base64'
+              });
+
+              // Create new tree with updated files
+              const newTree = await github.rest.git.createTree({
+                owner,
+                repo,
+                base_tree: currentCommit.data.tree.sha,
+                tree: [
+                  {
+                    path: 'build-scope-analyzer/action.yml',
+                    mode: '100644',
+                    type: 'blob',
+                    sha: actionYmlBlob.data.sha
+                  },
+                  {
+                    path: 'build-scope-analyzer/pyproject.toml',
+                    mode: '100644',
+                    type: 'blob',
+                    sha: pyprojectTomlBlob.data.sha
+                  }
+                ]
+              });
+
+              // Create new commit with explicit committer
+              const newCommit = await github.rest.git.createCommit({
+                owner,
+                repo,
+                message: `chore: bump version to ${version} [pre-merge]`,
+                tree: newTree.data.sha,
+                parents: [currentCommitSha],
+              });
+
+              // Update branch reference
+              await github.rest.git.updateRef({
+                owner,
+                repo,
+                ref: `heads/${branch}`,
+                sha: newCommit.data.sha
+              });
+
+              console.log(`Successfully updated branch ${branch} with new commit: ${newCommit.data.sha}`);
+
+            } catch (error) {
+              console.error('Error updating files via API:', error);
+              throw error;
+            }
+
+    # Require this job to pass before merging (set branch protection in GitHub UI)
diff --git a/.github/workflows/simple-release.yml b/.github/workflows/simple-release.yml
new file mode 100644
index 0000000..cc969c4
--- /dev/null
+++ b/.github/workflows/simple-release.yml
@@ -0,0 +1,87 @@
+name: Simple Release
+
+on:
+  pull_request:
+    types: [closed]
+    branches: [main]
+  workflow_dispatch:
+
+permissions:
+  contents: write
+  pull-requests: write
+  packages: write
+
+jobs:
+  create-release:
+    if: github.event.pull_request.merged == true || github.event_name == 'workflow_dispatch' && github.repository == 'stratus-test/stratus-actions' # Only run on the base repository
+    runs-on: ubuntu-latest
+    outputs:
+      new_version: ${{ steps.release.outputs.new_version }}
+      dirs: ${{ steps.find-docker.outputs.dirs }}
+    steps:
+      - uses: actions/checkout@v4
+        with:
+          fetch-depth: 0
+
+      - name: Create Release
+        id: release
+        uses: ./release
+        with:
+          draft: false
+          prerelease: false
+
+      - name: Find containerized actions
+        id: find-docker
+        run: |
+          find . -maxdepth 2 -mindepth 2 -name Dockerfile -exec dirname {} \; | sed 's|^./||' > docker_dirs.txt
+          echo "dirs=$(jq -c -R -s 'split("\n") | map(select(length > 0))' docker_dirs.txt)" >> $GITHUB_OUTPUT
+
+  build-and-push-images:
+    needs: create-release
+    if: github.repository == 'stratus-test/stratus-actions' # Only run
+    runs-on: ubuntu-latest
+    strategy:
+      matrix:
+        dir: ${{ fromJson(needs.create-release.outputs.dirs) }}
+    steps:
+      - uses: actions/checkout@v4
+        with:
+          fetch-depth: 0
+
+      - name: Fetch all tags
+        run: git fetch --tags
+
+      - name: Checkout the new tag
+        run: git checkout ${{ needs.create-release.outputs.new_version }}
+
+      - name: Set GITHUB_REF to tag
+        # This is necessary for the Docker metadata action to work correctly and belive we are in a tag context
+        run: echo "GITHUB_REF=refs/tags/${{ needs.create-release.outputs.new_version }}" >> $GITHUB_ENV
+
+      - name: Log in to GHCR
+        run: echo "${{ secrets.GITHUB_TOKEN }}" | docker login ghcr.io -u ${{ github.actor }} --password-stdin
+
+      - name: Set up Docker Buildx
+        uses: docker/setup-buildx-action@v3
+
+      - name: Extract Docker metadata
+        id: meta
+        uses: docker/metadata-action@v5
+        with:
+          images: ghcr.io/${{ github.repository }}/${{ matrix.dir }}
+          tags: |
+            type=semver,pattern={{version}}
+            type=semver,pattern=v{{major}}
+            latest
+
+      - name: Build and push Docker images
+        run: |
+          ORG_REPO=$(echo '${{ github.repository }}' | tr '[:upper:]' '[:lower:]')
+          IMAGE=ghcr.io/$ORG_REPO/${{ matrix.dir }}
+          docker buildx build \
+            --push \
+            --platform linux/amd64 \
+            --tag $IMAGE:sha-$(git rev-parse --short=7 ${{ github.sha }}) \
+            $(echo "${{ steps.meta.outputs.tags }}" | xargs -n 1 echo --tag) \
+            $(echo "${{ steps.meta.outputs.labels }}" | xargs -n 1 echo --label) \
+            ./${{ matrix.dir }}
diff --git a/.github/workflows/sync-from-upstream.yml b/.github/workflows/sync-from-upstream.yml
new file mode 100644
index 0000000..d18b6fd
--- /dev/null
+++ b/.github/workflows/sync-from-upstream.yml
@@ -0,0 +1,80 @@
+name: Sync from Upstream
+
+on:
+  schedule:
+    - cron: "0 * * * *" # every hour
+  workflow_dispatch:
+
+permissions:
+  contents: write
+
+jobs:
+  sync-upstream:
+    runs-on: ubuntu-latest
+    if: github.repository == 'hafslundecovannkraft/stratus-actions' # Only run on the forked repository
+    steps:
+      - name: Checkout fork
+        uses: actions/checkout@v4
+        with:
+          persist-credentials: false
+
+      - name: Set up Git
+        run: |
+          git config --global user.name "github-actions[bot]"
+          git config --global user.email "github-actions[bot]@users.noreply.github.com"
+
+      - name: Add upstream and fetch
+        env:
+          UPSTREAM_REPO: stratus-test/stratus-actions
+        run: |
+          git remote add upstream https://github.com/$UPSTREAM_REPO.git
+          git fetch upstream --tags
+          git fetch upstream main
+
+      - name: Push tags to origin
+        env:
+          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+        run: |
+          git push origin --tags
+
+      - name: Force update main branch from upstream
+        env:
+          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+        run: |
+          git checkout main
+          git reset --hard upstream/main
+          git push origin main --force
+
+      - name: Mirror latest release from upstream
+        uses: actions/github-script@v7
+        with:
+          script: |
+            const upstream = 'stratus-test/stratus-actions';
+            const [owner, repo] = upstream.split('/');
+
+            // Get all releases from upstream
+            const { data: upstreamReleases } = await github.rest.repos.listReleases({ owner, repo, per_page: 100 });
+
+            // Get all releases in the current repo
+            const { data: forkReleases } = await github.rest.repos.listReleases({
+              owner: context.repo.owner,
+              repo: context.repo.repo,
+              per_page: 100
+            });
+            const forkTags = new Set(forkReleases.map(r => r.tag_name));
+
+            // Mirror releases that don't exist in the fork
+            for (const release of upstreamReleases) {
+              if (!forkTags.has(release.tag_name)) {
+                await github.rest.repos.createRelease({
+                  owner: context.repo.owner,
+                  repo: context.repo.repo,
+                  tag_name: release.tag_name,
+                  name: release.name,
+                  body: release.body,
+                  draft: release.draft,
+                  prerelease: release.prerelease,
+                  target_commitish: release.target_commitish || 'main'
+                });
+              }
+            }
diff --git a/.github/workflows/test-actions.yml b/.github/workflows/test-actions.yml
new file mode 100644
index 0000000..e62125e
--- /dev/null
+++ b/.github/workflows/test-actions.yml
@@ -0,0 +1,223 @@
+name: Test Actions
+
+on:
+  pull_request:
+    types: [opened, synchronize]
+    paths:
+      - "hello-world/**"
+      - "release/**"
+      - "build-scope-analyzer/**"
+      - ".github/workflows/test-actions.yml"
+
+permissions:
+  contents: write
+  pull-requests: write
+  packages: write
+
+jobs:
+  test-hello-world:
+    name: Test Hello World Action
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+
+      - name: Test Hello World Action
+        uses: ./hello-world
+
+  test-release:
+    name: Test Release Action
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+        with:
+          fetch-depth: 0
+          token: ${{ secrets.GITHUB_TOKEN }}
+
+      - name: Configure Git
+        run: |
+          git config --global user.name "github-actions[bot]"
+          git config --global user.email "github-actions[bot]@users.noreply.github.com"
+
+      # Create a test scenario by modifying the release action to avoid actual push
+      - name: Mock Release Action for Testing
+        run: |
+          # Create a backup of the original action
+          cp release/action.yml release/action.yml.bak
+
+          # Modify the action to skip the actual git push
+          sed -i "" "s/git push origin/echo \"MOCK: Would push tag\"/g" release/action.yml || sed -i "s/git push origin/echo \"MOCK: Would push tag\"/g" release/action.yml
+
+      - name: Create Test Release
+        id: release
+        uses: ./release
+        with:
+          draft: true
+          prerelease: true
+
+      - name: Capture Release Details
+        id: release-details
+        if: steps.release.outputs.release_url != ''
+        run: |
+          # Get the release details using GitHub CLI
+          release_body=$(gh release view ${{ steps.release.outputs.new_version }} --json body -q .body)
+
+          # Save to file for multi-line handling
+          echo "$release_body" > release-notes.md
+
+          # Also get release metadata
+          gh release view ${{ steps.release.outputs.new_version }} --json name,tagName,isDraft,isPrerelease,createdAt > release-metadata.json
+        env:
+          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+
+      - name: Post Release Preview to PR
+        if: github.event_name == 'pull_request' && steps.release.outputs.release_url != ''
+        uses: actions/github-script@v7
+        with:
+          script: |
+            const fs = require('fs');
+
+            // Read the release notes and metadata
+            const releaseNotes = fs.readFileSync('release-notes.md', 'utf8');
+            const metadata = JSON.parse(fs.readFileSync('release-metadata.json', 'utf8'));
+
+            // Create a formatted comment
+            const comment = `## üéØ Release Action Test Results
+
+            ### Release Metadata
+            - **Version**: ${metadata.tagName}
+            - **Name**: ${metadata.name}
+            - **Type**: ${metadata.isDraft ? 'üìù Draft' : 'üì¢ Published'} ${metadata.isPrerelease ? '(Pre-release)' : ''}
+            - **Created**: ${new Date(metadata.createdAt).toLocaleString()}
+            - **Bump Type**: ${{ steps.release.outputs.bump_type }}
+            - **Previous Version**: ${{ steps.release.outputs.previous_version }}
+
+            ### Release Notes Preview
+
+            <details>
+            <summary>Click to expand release notes</summary>
+
+            ${releaseNotes}
+
+            </details>
+
+            ### Release URL
+            üîó [View test release](${{ steps.release.outputs.release_url }})
+
+            > **Note**: This test release will be automatically deleted after verification.`;
+
+            // Post the comment
+            await github.rest.issues.createComment({
+              owner: context.repo.owner,
+              repo: context.repo.repo,
+              issue_number: context.issue.number,
+              body: comment
+            });
+
+      - name: Verify Release
+        run: |
+          echo "‚úÖ Release created successfully"
+          echo "Version: ${{ steps.release.outputs.new_version }}"
+          echo "Previous: ${{ steps.release.outputs.previous_version }}"
+          echo "Bump type: ${{ steps.release.outputs.bump_type }}"
+          echo "URL: ${{ steps.release.outputs.release_url }}"
+
+          if [[ -f release-notes.md ]]; then
+            echo -e "\nüìù Release Notes:"
+            cat release-notes.md
+          fi
+
+      - name: Delete Test Release
+        if: always()
+        run: |
+          # Delete the release if it was created
+          if [[ -n "${{ steps.release.outputs.new_version }}" ]]; then
+            echo "üóëÔ∏è Cleaning up test release..."
+            gh release delete ${{ steps.release.outputs.new_version }} --yes || true
+          fi
+
+          # Restore the original action
+          mv release/action.yml.bak release/action.yml || true
+        env:
+          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+
+  test-build-scope-analyzer:
+    name: Test Build Scope Analyzer
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+        with:
+          fetch-depth: 0
+
+      - name: Log in to GHCR
+        run: echo "${{ secrets.GITHUB_TOKEN }}" | docker login ghcr.io -u ${{ github.actor }} --password-stdin
+
+      - name: Setup Test Environment
+        run: |
+          # Create test files
+          mkdir -p src/helloworld
+          echo "FROM node:18" > src/helloworld/Dockerfile
+          echo "WORKDIR /app" >> src/helloworld/Dockerfile
+          echo "COPY . ." >> src/helloworld/Dockerfile
+          echo "CMD [\"node\", \"index.js\"]" >> src/helloworld/Dockerfile
+
+          echo "name: hello-world" > src/helloworld/app.yaml
+          echo "version: 1.0.0" >> src/helloworld/app.yaml
+          echo "description: Test application" >> src/helloworld/app.yaml
+
+          # Create a test branch to compare against
+          git checkout -b test-base
+          git add .
+          git commit -m "Initial test commit" || true
+
+          # Make changes on a new branch
+          git checkout -b test-changes
+          echo "console.log('Hello World');" > src/helloworld/index.js
+          mkdir -p src/another-app
+          echo "FROM alpine:latest" > src/another-app/Dockerfile
+          git add .
+
+      - name: Build Docker image for Build Scope Analyzer
+        run: |
+          SHORT_SHA=$(git rev-parse --short=7 HEAD)
+          ORG_REPO=$(echo "${{ github.repository }}" | tr '[:upper:]' '[:lower:]')
+          docker build -t ghcr.io/$ORG_REPO/build-scope-analyzer:sha-$SHORT_SHA ./build-scope-analyzer
+
+      - name: Push Docker image to GHCR
+        run: |
+          SHORT_SHA=$(git rev-parse --short=7 HEAD)
+          ORG_REPO=$(echo "${{ github.repository }}" | tr '[:upper:]' '[:lower:]')
+          docker push ghcr.io/$ORG_REPO/build-scope-analyzer:sha-$SHORT_SHA
+
+      - name: Analyze Build Scope (with changes) using container
+        id: scope
+        run: |
+          SHORT_SHA=$(git rev-parse --short=7 HEAD)
+          ORG_REPO=$(echo "${{ github.repository }}" | tr '[:upper:]' '[:lower:]')
+          docker run --rm \
+            -v "$(pwd):/github/workspace" \
+            -e GITHUB_WORKSPACE=/github/workspace \
+            ghcr.io/$ORG_REPO/build-scope-analyzer:sha-$SHORT_SHA \
+            --root-path /github/workspace --ref test-base --output-format json > matrix.json
+          echo "matrix=$(cat matrix.json | jq -c .)" >> $GITHUB_OUTPUT
+
+      - name: Verify Analysis Results
+        run: |
+          echo "Matrix: $(cat matrix.json)"
+          cat matrix.json | jq .
+
+      - name: Test with Include Pattern using container
+        id: scope-include
+        run: |
+          SHORT_SHA=$(git rev-parse --short=7 HEAD)
+          ORG_REPO=$(echo "${{ github.repository }}" | tr '[:upper:]' '[:lower:]')
+          docker run --rm \
+            -v "$(pwd):/github/workspace" \
+            -e GITHUB_WORKSPACE=/github/workspace \
+            ghcr.io/$ORG_REPO/build-scope-analyzer:sha-$SHORT_SHA \
+            --root-path /github/workspace --ref test-base --include-pattern 'src/helloworld/*' --output-format json > matrix-include.json
+          echo "matrix=$(cat matrix-include.json | jq -c .)" >> $GITHUB_OUTPUT
+
+      - name: Verify Include Pattern Results
+        run: |
+          echo "Matrix (include pattern): $(cat matrix-include.json)"
+          cat matrix-include.json | jq .
diff --git a/.gitignore b/.gitignore
new file mode 100644
index 0000000..6ca2197
--- /dev/null
+++ b/.gitignore
@@ -0,0 +1,222 @@
+# Byte-compiled / optimized / DLL files
+**/__pycache__/
+*.py[cod]
+*$py.class
+
+# C extensions
+*.so
+
+# Distribution / packaging
+.Python
+build/
+develop-eggs/
+dist/
+downloads/
+eggs/
+.eggs/
+lib/
+lib64/
+parts/
+sdist/
+var/
+wheels/
+share/python-wheels/
+*.egg-info/
+.installed.cfg
+*.egg
+MANIFEST
+
+# PyInstaller
+#  Usually these files are written by a python script from a template
+#  before PyInstaller builds the exe, so as to inject date/other infos into it.
+*.manifest
+*.spec
+
+# Installer logs
+pip-log.txt
+pip-delete-this-directory.txt
+
+# Unit test / coverage reports
+htmlcov/
+.tox/
+.nox/
+.coverage
+.coverage.*
+.cache
+nosetests.xml
+coverage.xml
+*.cover
+*.py,cover
+.hypothesis/
+.pytest_cache/
+cover/
+
+# Translations
+*.mo
+*.pot
+
+# Django stuff:
+*.log
+local_settings.py
+db.sqlite3
+db.sqlite3-journal
+
+# Flask stuff:
+instance/
+.webassets-cache
+
+# Scrapy stuff:
+.scrapy
+
+# Sphinx documentation
+docs/_build/
+
+# PyBuilder
+.pybuilder/
+target/
+
+# Jupyter Notebook
+.ipynb_checkpoints
+
+# IPython
+profile_default/
+ipython_config.py
+
+# pyenv
+#   For a library or package, you might want to ignore these files since the code is
+#   intended to run in multiple environments; otherwise, check them in:
+# .python-version
+
+# pipenv
+#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
+#   However, in case of collaboration, if having platform-specific dependencies or dependencies
+#   having no cross-platform support, pipenv may install dependencies that don't work, or not
+#   install all needed dependencies.
+#Pipfile.lock
+
+# UV
+#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.
+#   This is especially recommended for binary packages to ensure reproducibility, and is more
+#   commonly ignored for libraries.
+#uv.lock
+
+# poetry
+#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
+#   This is especially recommended for binary packages to ensure reproducibility, and is more
+#   commonly ignored for libraries.
+#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
+#poetry.lock
+
+# pdm
+#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
+#pdm.lock
+#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
+#   in version control.
+#   https://pdm.fming.dev/latest/usage/project/#working-with-version-control
+.pdm.toml
+.pdm-python
+.pdm-build/
+
+# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
+__pypackages__/
+
+# Celery stuff
+celerybeat-schedule
+celerybeat.pid
+
+# SageMath parsed files
+*.sage.py
+
+# Environments
+.env
+.venv
+env/
+venv/
+ENV/
+env.bak/
+venv.bak/
+
+# Spyder project settings
+.spyderproject
+.spyproject
+
+# Rope project settings
+.ropeproject
+
+# mkdocs documentation
+/site
+
+# mypy
+.mypy_cache/
+.dmypy.json
+dmypy.json
+
+# Pyre type checker
+.pyre/
+
+# pytype static type analyzer
+.pytype/
+
+# Cython debug symbols
+cython_debug/
+
+# PyCharm
+#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
+#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
+#  and can be added to the global gitignore or merged into this file.  For a more nuclear
+#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
+#.idea/
+
+# Ruff stuff:
+.ruff_cache/
+
+# PyPI configuration file
+.pypirc
+
+# Terraform specific ignores
+# Local .terraform directories
+**/.terraform/*
+
+# .tfstate files
+*.tfstate
+*.tfstate.*
+
+# Crash log files
+crash.log
+crash.*.log
+
+# Exclude all .tfvars files, which are likely to contain sensitive data, such as
+# password, private keys, and other secrets. These should not be part of version control
+# as they are data points which are potentially sensitive and subject to change
+# depending on the environment.
+*.tfvars
+*.tfvars.json
+
+# Ignore override files as they are usually used to override resources locally and so
+# are not checked in
+override.tf
+override.tf.json
+*_override.tf
+*_override.tf.json
+
+# Include override files you do wish to add to version control using negated pattern
+# !example_override.tf
+
+# Include tfvars files you do wish to add to version control using negated pattern
+# !example.tfvars
+# !example.tfvars.json
+
+# Ignore CLI configuration files
+.terraformrc
+terraform.rc
+.terraform.lock.hcl
+
+# Terraform plan output files
+*tfplan*
+
+# Ignore local _temp folders
+**/_temp/
+
+# Ignore files often genereated or used by AI tools
+git.diff
+PR.md
\ No newline at end of file
diff --git a/README.md b/README.md
new file mode 100644
index 0000000..94e989a
--- /dev/null
+++ b/README.md
@@ -0,0 +1,188 @@
+# Stratus GitHub Actions
+
+> **‚ö†Ô∏è NOTE: The canonical and maintained repository is [`stratus-test/stratus-actions`](https://github.com/stratus-test/stratus-actions). All maintenance and development are performed in the `stratus-test` organization. This repository may be mirrored or forked in other organizations (e.g., HafslundEcoVannkraft), but all issues, pull requests, and releases should be managed in `stratus-test`.**
+>
+> **This arrangement is temporary due to current policy constraints that prevent publishing public packages in the HafslundEcoVannkraft organization. Once these policy issues are resolved, the canonical repository location may change.**
+
+Welcome to `stratus-actions`! This repository hosts a collection of reusable composite GitHub Actions to streamline workflows across repositories. The repository is public, you can easily share actions with any repository, ensuring consistency and reducing duplicated code.
+
+## Table of Contents
+
+- [Stratus GitHub Actions](#stratus-github-actions)
+  - [Table of Contents](#table-of-contents)
+  - [About](#about)
+    - [Key Benefits](#key-benefits)
+  - [Repository Structure](#repository-structure)
+  - [Usage](#usage)
+  - [Available Actions](#available-actions)
+    - [Hello World Action](#hello-world-action)
+      - [Example Using Hello World Action](#example-using-hello-world-action)
+    - [Simple Version Bump and Release Action](#simple-version-bump-and-release-action)
+    - [Build Scope Analyzer Action](#build-scope-analyzer-action)
+  - [Contributing](#contributing)
+    - [Release Process](#release-process)
+      - [1. Version Bumping (Workflow Logic)](#1-version-bumping-workflow-logic)
+      - [2. Release Notes Categorization (`.github/release.yml`)](#2-release-notes-categorization-githubreleaseyml)
+    - [Development Guidelines](#development-guidelines)
+    - [Version Control](#version-control)
+  - [License](#license)
+
+## About
+
+The `stratus-actions` repository is designed to simplify and standardize workflows across projects by providing a central source of reusable composite GitHub Actions. Each action is defined within its own folder at the repository root, making it easy to reference them directly from any repository.
+
+### Key Benefits
+
+- **Reusable**: Use the same action in multiple workflows and repositories, improving consistency.
+- **Public Access**: As a public repository, actions here can be used in both public and private/internal repositories.
+- **Containerized Actions**: Some actions (like build-scope-analyzer) are distributed as Docker containers for maximum compatibility and reproducibility.
+- **Version Control**: Keep track of changes to actions across repositories, ensuring stability with tagged versions.
+- **Simple and Reliable**: Actions use GitHub's native features without external dependencies.
+
+## Repository Structure
+
+The repository is organized with each action in its own folder at the root level:
+
+```plaintext
+stratus-actions/
+‚îú‚îÄ‚îÄ build-scope-analyzer/
+‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
+‚îÇ   ‚îú‚îÄ‚îÄ README.md
+‚îÇ   ‚îú‚îÄ‚îÄ action.yml
+‚îÇ   ‚îú‚îÄ‚îÄ example-outputs.md
+‚îÇ   ‚îú‚îÄ‚îÄ example-workflow.yml
+‚îÇ   ‚îú‚îÄ‚îÄ main.py
+‚îÇ   ‚îî‚îÄ‚îÄ pyproject.toml
+‚îú‚îÄ‚îÄ hello-world/
+‚îÇ   ‚îú‚îÄ‚îÄ README.md
+‚îÇ   ‚îú‚îÄ‚îÄ action.yml
+‚îÇ   ‚îî‚îÄ‚îÄ entrypoint.sh
+‚îú‚îÄ‚îÄ release/
+‚îÇ   ‚îú‚îÄ‚îÄ README.md
+‚îÇ   ‚îî‚îÄ‚îÄ action.yml
+‚îú‚îÄ‚îÄ .github/
+‚îÇ   ‚îî‚îÄ‚îÄ workflows/
+‚îî‚îÄ‚îÄ README.md
+```
+
+Each action has its own documentation explaining its specific usage and configuration options.
+
+## Usage
+
+To use an action from this repository, reference it in your workflow file with the following syntax:
+
+```yaml
+uses: HafslundEcoVannkraft/stratus-actions/[action-name]@v1.0.0
+```
+
+Replace:
+
+- `[action-name]` with the specific action folder name (e.g., `release`, `hello-world`, `build-scope-analyzer`)
+- `@v1.0.0` with the desired version tag
+
+## Available Actions
+
+### Hello World Action
+
+A simple example action that demonstrates the basic structure and usage of composite actions. For more information, see the [hello-world action documentation](hello-world/README.md).
+
+#### Example Using Hello World Action
+
+```yaml
+name: Hello World Example
+
+on:
+  workflow_dispatch:
+
+jobs:
+  hello:
+    runs-on: ubuntu-latest
+    steps:
+      - name: Say Hello
+        uses: HafslundEcoVannkraft/stratus-actions/hello-world@v1.0.0
+```
+
+### Simple Version Bump and Release Action
+
+A lightweight action that automates version management and release creation using GitHub's native features:
+
+**Key Features:**
+
+- üîÑ Automatic version bumping based on PR labels or commit messages
+- üìù Native GitHub release notes (no external dependencies)
+- üè∑Ô∏è Semantic versioning support
+- üéØ Zero configuration required
+- üìã Simple and reliable
+
+For detailed information about this action, see the [release action documentation](release/README.md).
+
+### Build Scope Analyzer Action
+
+A containerized action (Python, Docker) that analyzes git changes to determine what needs to be built, generating a strategy matrix for GitHub Actions workflows. This action helps optimize CI/CD pipelines by only building what has changed.
+
+**Key Features:**
+
+- üîç Analyzes git changes to identify modified directories
+- üìä Generates GitHub Actions strategy matrix
+- üóëÔ∏è Identifies deleted folders for cleanup
+- üéØ Supports include/exclude patterns for fine-grained control
+- üê≥ Runs as a Docker container for consistent, isolated execution
+
+For detailed information about this action, see the [build-scope-analyzer action documentation](build-scope-analyzer/README.md).
+
+## Contributing
+
+Contributions are welcome! If you'd like to add an action, improve existing ones, or report an issue, please follow these guidelines:
+
+1. **Fork the Repository**: Create a fork and make your changes.
+2. **Follow Commit Conventions**: Use conventional commit messages:
+   - `feat:` or `feat()` for new features
+   - `fix:` or `fix()` for bug fixes
+   - Include `BREAKING` in PR title for breaking changes
+3. **Open a Pull Request**: Submit a PR with a clear description of your changes.
+4. **Action Documentation**: Ensure each action has a `README.md` in its folder explaining its usage.
+
+### Release Process
+
+This repository uses an automated release process. The first release is v1.0.0, and all previous history has been reset for clarity and maintainability.
+
+#### 1. Version Bumping (Workflow Logic)
+
+When a Pull Request is merged to `main`, the workflow determines the version bump based on PR labels:
+
+- **Major** (vX.0.0): PRs with `breaking-change` or `major` label
+- **Minor** (vX.Y.0): PRs with `enhancement`, `feature`, or `minor` label
+- **Patch** (vX.Y.Z): All other PRs (default)
+
+#### 2. Release Notes Categorization (`.github/release.yml`)
+
+GitHub automatically categorizes merged PRs in release notes based on labels:
+
+- PRs with `enhancement` or `feature` labels ‚Üí üöÄ Features
+- PRs with `bug` or `bugfix` labels ‚Üí üêõ Bug Fixes
+- PRs with `documentation` label ‚Üí üìö Documentation
+- PRs with `breaking-change` label ‚Üí ‚ö†Ô∏è Breaking Changes
+- PRs with `maintenance` or `chore` labels ‚Üí üîß Maintenance
+
+**Important**: The `.github/release.yml` file ONLY controls how release notes are displayed. It does NOT determine version numbers - that's handled by the workflow logic.
+
+### Development Guidelines
+
+- Test actions in a separate branch or fork before merging to `main`
+- Use meaningful commit messages following the conventional commit format
+- Each action should have README.md documentation
+- Update examples in documentation to reflect any changes
+- Test changes with workflows in your fork before submitting PRs
+
+### Version Control
+
+The repository automatically handles versioning through the release action. You don't need to manually create tags or releases. Just follow these practices:
+
+1. Use conventional commit messages to indicate change type
+2. For pre-releases, use appropriate prefixes in commit messages
+3. Let the automated pipeline handle version bumping and release creation
+4. Check the generated release notes and edit if necessary
+
+## License
+
+MIT
diff --git a/build-scope-analyzer/.dockerignore b/build-scope-analyzer/.dockerignore
new file mode 100644
index 0000000..21a9ca7
--- /dev/null
+++ b/build-scope-analyzer/.dockerignore
@@ -0,0 +1,36 @@
+# Git
+.git
+.gitignore
+
+# Testing
+**/__pycache__
+**/*.pyc
+**/*.pyo
+**/*.pyd
+.pytest_cache
+test*
+tests/
+
+# Docker
+Dockerfile
+.dockerignore
+docker-compose.yml
+run-docker.sh
+run-compose.sh
+test-usage.sh
+
+# Documentation
+*.md
+LICENSE
+CONTRIBUTING*
+!README.md
+
+# GitHub
+.github/
+
+# Temporary files
+*.log
+*.swp
+*.swo
+*~
+.DS_Store
diff --git a/build-scope-analyzer/.github/workflows/build-and-publish.yml b/build-scope-analyzer/.github/workflows/build-and-publish.yml
new file mode 100644
index 0000000..234d26c
--- /dev/null
+++ b/build-scope-analyzer/.github/workflows/build-and-publish.yml
@@ -0,0 +1,53 @@
+name: Build and Publish Docker Image
+
+on:
+  push:
+    branches:
+      - main
+    paths:
+      - "stratus-actions/build-scope-analyzer/**"
+  workflow_dispatch:
+
+jobs:
+  build-and-push:
+    runs-on: ubuntu-latest
+    permissions:
+      contents: read
+      packages: write
+
+    steps:
+      - name: Checkout repository
+        uses: actions/checkout@v4
+
+      - name: Set up Docker Buildx
+        uses: docker/setup-buildx-action@v3
+
+      - name: Login to GitHub Container Registry
+        uses: docker/login-action@v3
+        with:
+          registry: ghcr.io
+          username: ${{ github.actor }}
+          password: ${{ secrets.GITHUB_TOKEN }}
+
+      - name: Extract metadata for Docker
+        id: meta
+        uses: docker/metadata-action@v5
+        with:
+          images: ghcr.io/${{ github.repository_owner }}/stratus-actions/build-scope-analyzer
+          tags: |
+            type=semver,pattern={{version}}
+            type=semver,pattern={{major}}.{{minor}}
+            type=semver,pattern={{major}}
+            type=ref,event=branch
+            type=sha,format=short
+            latest
+
+      - name: Build and push Docker image
+        uses: docker/build-push-action@v5
+        with:
+          context: ./stratus-actions/build-scope-analyzer
+          push: true
+          tags: ${{ steps.meta.outputs.tags }}
+          labels: ${{ steps.meta.outputs.labels }}
+          cache-from: type=gha
+          cache-to: type=gha,mode=max
diff --git a/build-scope-analyzer/Dockerfile b/build-scope-analyzer/Dockerfile
new file mode 100644
index 0000000..e166932
--- /dev/null
+++ b/build-scope-analyzer/Dockerfile
@@ -0,0 +1,35 @@
+FROM alpine:latest AS build
+
+WORKDIR /app
+
+RUN apk --no-cache upgrade && apk --no-cache add gcc musl-dev python3 py3-pip
+
+COPY pyproject.toml /app/
+RUN python3 -m venv /venv
+RUN /venv/bin/pip install --no-cache-dir --upgrade pip setuptools wheel && \
+    /venv/bin/pip install --no-cache-dir .
+
+FROM alpine:latest
+
+RUN apk --no-cache add git python3 py3-pip
+
+LABEL org.opencontainers.image.source="https://github.com/stratus-test/stratus-actions"
+LABEL org.opencontainers.image.description="Build Scope Analyzer - Analyze git changes to identify what needs to be built"
+LABEL org.opencontainers.image.licenses=MIT
+
+COPY --from=build /venv /venv
+ENV PATH="/venv/bin:$PATH"
+ENV PYTHONPATH="/venv/lib/python3.14/site-packages"
+
+WORKDIR /github/workspace
+COPY main.py /app/
+
+RUN addgroup -S appgroup && adduser -S appuser -G appgroup && \
+    chown -R appuser:appgroup /app
+USER appuser
+
+RUN git config --global --add safe.directory /github/workspace
+
+ENTRYPOINT ["python", "/app/main.py"]
+
+CMD ["--help"]
\ No newline at end of file
diff --git a/build-scope-analyzer/README.md b/build-scope-analyzer/README.md
new file mode 100644
index 0000000..96c66cf
--- /dev/null
+++ b/build-scope-analyzer/README.md
@@ -0,0 +1,141 @@
+# Build Scope Analyzer
+
+## Overview
+
+Build Scope Analyzer is a GitHub Action and CLI tool that analyzes changes in a git repository to determine which applications and containers need to be built, deployed, or cleaned up. It is designed for monorepos and multi-app repositories, especially those using containerized applications.
+
+- **Smart Change Detection:** Analyzes git diffs to identify changed, deleted, and renamed files and folders
+- **Deletion Tracking:** Detects deleted apps or containers for proper cleanup
+- **Multi-Container Support:** Handles multiple apps and containers per repo
+- **Custom Docker Build Context:** Supports custom Docker build contexts via `# @context: ...` in Dockerfiles
+- **Matrix Outputs:** Generates strategy matrices for parallel builds and deployments
+- **Secure & Reproducible:** Runs in a minimal, non-root Docker container for consistent results
+
+## Inputs
+
+| Input             | Description                                                    | Default                   |
+| ----------------- | -------------------------------------------------------------- | ------------------------- |
+| `root-path`       | Root path to search for changes (defaults to GITHUB_WORKSPACE) | `${{ github.workspace }}` |
+| `include-pattern` | Glob pattern for paths to include (e.g., `apps/*`)             | `*`                       |
+| `exclude-pattern` | Glob pattern for paths to exclude (e.g., `docs/*`)             | `""`                      |
+| `ref`             | Git ref to compare against (defaults to automatic detection)   | `""`                      |
+
+## Outputs
+
+| Output   | Description                                       |
+| -------- | ------------------------------------------------- |
+| `matrix` | JSON matrix structure with all app/container data |
+| `ref`    | Git ref used for comparison                       |
+
+## Usage as a GitHub Action
+
+```yaml
+- name: Analyze Build Scope
+  id: analyze
+  uses: HafslundEcoVannkraft/stratus-actions/build-scope-analyzer@v1.0.0
+  with:
+    root-path: ${{ github.workspace }}
+    include-pattern: "apps/*"
+    exclude-pattern: "tests/*"
+```
+
+- The action outputs a `matrix` JSON object with all changed, all, and deleted apps/containers, and the `ref` used for comparison.
+- See the [example-workflow.yml](./example-workflow.yml) for a full pipeline example.
+
+## Usage as a Docker CLI Tool
+
+```bash
+docker run --rm \
+  -v "$(git rev-parse --show-toplevel):/github/workspace" \
+  -e GITHUB_WORKSPACE=/github/workspace \
+  ghcr.io/stratus-test/stratus-actions/build-scope-analyzer:latest \
+  --root-path /github/workspace
+```
+
+- All arguments after the image name are passed to the Python program.
+- The container checks for a valid git repository using git commands.
+- If not run inside a git repo, a warning is shown and results may not be as expected.
+- The image source is now canonical in this repository. This is the first production release (v1.0.0) after a full history reset.
+
+## Command-line Arguments
+
+Run with `--help` to see all options:
+
+```bash
+docker run --rm -v "$(git rev-parse --show-toplevel):/github/workspace" -e GITHUB_WORKSPACE=/github/workspace ghcr.io/stratus-test/stratus-actions/build-scope-analyzer:latest --help
+```
+
+- `--output-format github` (default) outputs for GitHub Actions
+- `--output-format json` outputs plain JSON for CLI use
+- `--mock-git` enables mock mode for local testing without a git repo
+
+## Example Output Structure
+
+The action outputs a matrix with the following structure:
+
+```json
+{
+  "apps": {
+    "updated": [...],
+    "all": [...],
+    "deleted": [...],
+    "has_updates": true,
+    "has_deletions": false
+  },
+  "containers": {
+    "updated": [...],
+    "all": [...],
+    "deleted": [...],
+    "has_updates": true,
+    "has_deletions": false
+  },
+  "ref": "origin/main"
+}
+```
+
+- See [example-outputs.md](./example-outputs.md) for more scenarios.
+
+## How It Works
+
+- Detects changed, deleted, and renamed files using git diff
+- Groups changes by app/container folder
+- Finds Dockerfiles and app.yaml/app.yml in each folder
+- Outputs a matrix for use in downstream jobs (build, deploy, cleanup)
+
+## Development & Testing
+
+- The action is fully tested via GitHub Actions workflows ([test-actions.yml](../.github/workflows/test-actions.yml)).
+- For local testing:
+  ```bash
+  docker build -t build-scope-analyzer .
+  docker run --rm -v "$(git rev-parse --show-toplevel):/github/workspace" -e GITHUB_WORKSPACE=/github/workspace build-scope-analyzer --root-path /github/workspace
+  ```
+- To run Python tests locally:
+  Use standard Python unittest or pytest in the `/tests` directory.
+
+## Troubleshooting & FAQ
+
+- **Q: What happens if not run in a git repo?**
+  - A: The action will warn and may not produce expected results. Use `--mock-git` for local testing.
+- **Q: How do I debug missing or unexpected changes?**
+  - A: Check the `ref` used for comparison and ensure your include/exclude patterns are correct.
+- **Q: How do I use this in a fork or mirror repo?**
+  - A: Ensure you have access to the correct git history and set the `ref` input if needed.
+
+## Versioning & Release
+
+- Versioning is managed via `pyproject.toml` and the release workflow. The first release is v1.0.0 after a full history reset.
+- The Docker image is published to GHCR as `ghcr.io/stratus-test/stratus-actions/build-scope-analyzer:v1.0.0`.
+- The next version is previewed in PRs by the `pre-merge-version.yml` workflow and finalized on merge to main.
+
+## Migration Notes
+
+- The action is now fully containerized and uses `main.py` as the entrypoint.
+- All legacy scripts and files (e.g., `entrypoint.sh`, `docker-compose.yml`, `version.sh`, `test.sh`) are deprecated and removed.
+- See this README for all up-to-date usage and development instructions.
+
+## Contributing
+
+- Contributions are welcome! Please open issues or pull requests in the canonical repository.
+- See the [test-actions.yml](../.github/workflows/test-actions.yml) for test scenarios.
+- For questions, open a discussion or contact the maintainers.
diff --git a/build-scope-analyzer/action.yml b/build-scope-analyzer/action.yml
new file mode 100644
index 0000000..f84c4e9
--- /dev/null
+++ b/build-scope-analyzer/action.yml
@@ -0,0 +1,63 @@
+name: "Build Scope Analyzer"
+description: "Analyze git diff to identify what needs to be built and generate strategy matrix"
+author: "Stratus Team"
+
+inputs:
+  root-path:
+    description: "Root path to search for changes (defaults to GITHUB_WORKSPACE)"
+    required: false
+    default: ${{ github.workspace }}
+  include-pattern:
+    description: 'Glob pattern for paths to include (e.g., "apps/*")'
+    required: false
+    default: "*"
+  exclude-pattern:
+    description: 'Glob pattern for paths to exclude (e.g., "docs/*")'
+    required: false
+    default: ""
+  ref:
+    description: "Git ref to compare against (defaults to automatic detection)"
+    required: false
+    default: ""
+
+outputs:
+  matrix:
+    description: |
+      Clean, focused JSON matrix structure with the following sub-properties:
+
+      - matrix.apps: Container app deployment information
+        - matrix.apps.updated: Array of changed apps with app.yaml/app.yml
+        - matrix.apps.all: Array of all apps with app.yaml/app.yml
+        - matrix.apps.deleted: Array of deleted apps
+        - matrix.apps.has_updates: Boolean indicating if any apps were changed
+        - matrix.apps.has_deletions: Boolean indicating if any apps were deleted
+
+      - matrix.containers: Docker container build information
+        - matrix.containers.updated: Array of changed containers, each with:
+            - path: App folder path
+            - context: Docker build context (from @context or defaults to app folder)
+            - app_name: App name
+            - dockerfile: Dockerfile info (path, name, suffix)
+            - image_name: Image name for tagging
+            - container_name: Canonical container name
+        - matrix.containers.all: Array of all containers (same structure as above)
+        - matrix.containers.deleted: Array of deleted containers
+        - matrix.containers.has_updates: Boolean indicating if any containers were changed
+        - matrix.containers.has_deletions: Boolean indicating if any containers were deleted
+
+      - matrix.ref: Git ref used for comparison
+  ref:
+    description: "Git ref used for comparison"
+
+runs:
+  using: "docker"
+  image: "docker://ghcr.io/Stratus-TEST/stratus-actions/build-scope-analyzer:v3.1.8"
+  args:
+    - "--root-path"
+    - "${{ inputs.root-path }}"
+    - "--include-pattern"
+    - "${{ inputs.include-pattern }}"
+    - "--exclude-pattern"
+    - "${{ inputs.exclude-pattern }}"
+    - "--ref"
+    - "${{ inputs.ref }}"
diff --git a/build-scope-analyzer/example-outputs.md b/build-scope-analyzer/example-outputs.md
new file mode 100644
index 0000000..e75ba69
--- /dev/null
+++ b/build-scope-analyzer/example-outputs.md
@@ -0,0 +1,826 @@
+# Build Scope Analyzer - Example Outputs
+
+This document shows example outputs from the build scope analyzer for various scenarios.
+
+## Scenario 1: Simple App with Changes
+
+**Repository structure:**
+
+```
+apps/
+‚îú‚îÄ‚îÄ web-api/
+‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
+‚îÇ   ‚îú‚îÄ‚îÄ app.yaml
+‚îÇ   ‚îî‚îÄ‚îÄ src/
+‚îî‚îÄ‚îÄ frontend/
+    ‚îú‚îÄ‚îÄ Dockerfile
+    ‚îî‚îÄ‚îÄ src/
+```
+
+**Changes:** Modified files in `apps/web-api/`
+
+**Analyzer Output (New Format):**
+
+```json
+{
+  "apps": {
+    "updated": [
+      { "path": "apps/web-api", "app_name": "web-api", "app_config": "apps/web-api/app.yaml" }
+    ],
+    "all": [
+      { "path": "apps/web-api", "app_name": "web-api", "app_config": "apps/web-api/app.yaml" },
+      { "path": "apps/frontend", "app_name": "frontend", "app_config": null }
+    ],
+    "deleted": [],
+    "has_updates": true,
+    "has_deletions": false
+  },
+  "containers": {
+    "updated": [
+      {
+        "path": "apps/web-api",
+        "app_name": "web-api",
+        "container_name": "web-api",
+        "context": "apps/web-api",
+        "dockerfile": {
+          "path": "apps/web-api/Dockerfile",
+          "name": "Dockerfile",
+          "suffix": ""
+        }
+      }
+    ],
+    "all": [
+      {
+        "path": "apps/web-api",
+        "app_name": "web-api",
+        "container_name": "web-api",
+        "context": "apps/web-api",
+        "dockerfile": {
+          "path": "apps/web-api/Dockerfile",
+          "name": "Dockerfile",
+          "suffix": ""
+        }
+      },
+      {
+        "path": "apps/frontend",
+        "app_name": "frontend",
+        "container_name": "frontend",
+        "context": "apps/frontend",
+        "dockerfile": {
+          "path": "apps/frontend/Dockerfile",
+          "name": "Dockerfile",
+          "suffix": ""
+        }
+      }
+    ],
+    "deleted": [],
+    "has_updates": true,
+    "has_deletions": false
+  },
+  "ref": "origin/main"
+}
+```
+
+**GitHub Actions Outputs:**
+
+```
+matrix={...see above...}
+ref=origin/main
+```
+
+## Scenario 2: Multi-Container App
+
+**Repository structure:**
+
+```
+apps/
+‚îî‚îÄ‚îÄ secure-api/
+    ‚îú‚îÄ‚îÄ Dockerfile
+    ‚îú‚îÄ‚îÄ Dockerfile.auth
+    ‚îú‚îÄ‚îÄ Dockerfile.logger
+    ‚îú‚îÄ‚îÄ app.yaml
+    ‚îî‚îÄ‚îÄ src/
+```
+
+**Changes:** Added `Dockerfile.logger` to `apps/secure-api/`
+
+**Analyzer Output:**
+
+```json
+{
+  "apps": {
+    "updated": [
+      {
+        "path": "apps/secure-api",
+        "app_name": "secure-api",
+        "app_config": "apps/secure-api/app.yaml"
+      }
+    ],
+    "all": [
+      {
+        "path": "apps/secure-api",
+        "app_name": "secure-api",
+        "app_config": "apps/secure-api/app.yaml"
+      }
+    ],
+    "deleted": [],
+    "has_updates": true,
+    "has_deletions": false
+  },
+  "containers": {
+    "updated": [
+      {
+        "path": "apps/secure-api",
+        "app_name": "secure-api",
+        "container_name": "secure-api-logger",
+        "context": "apps/secure-api",
+        "dockerfile": {
+          "path": "apps/secure-api/Dockerfile.logger",
+          "name": "Dockerfile.logger",
+          "suffix": ".logger"
+        }
+      }
+    ],
+    "all": [
+      {
+        "path": "apps/secure-api",
+        "app_name": "secure-api",
+        "container_name": "secure-api",
+        "context": "apps/secure-api",
+        "dockerfile": {
+          "path": "apps/secure-api/Dockerfile",
+          "name": "Dockerfile",
+          "suffix": ""
+        }
+      },
+      {
+        "path": "apps/secure-api",
+        "app_name": "secure-api",
+        "container_name": "secure-api-auth",
+        "context": "apps/secure-api",
+        "dockerfile": {
+          "path": "apps/secure-api/Dockerfile.auth",
+          "name": "Dockerfile.auth",
+          "suffix": ".auth"
+        }
+      },
+      {
+        "path": "apps/secure-api",
+        "app_name": "secure-api",
+        "container_name": "secure-api-logger",
+        "context": "apps/secure-api",
+        "dockerfile": {
+          "path": "apps/secure-api/Dockerfile.logger",
+          "name": "Dockerfile.logger",
+          "suffix": ".logger"
+        }
+      }
+    ],
+    "deleted": [],
+    "has_updates": true,
+    "has_deletions": false
+  },
+  "ref": "HEAD~1"
+}
+```
+
+## Scenario 3: Deleted Sidecar Container
+
+**Repository structure:**
+
+```
+apps/
+‚îî‚îÄ‚îÄ payment-service/
+    ‚îú‚îÄ‚îÄ Dockerfile
+    ‚îú‚îÄ‚îÄ app.yaml
+    ‚îî‚îÄ‚îÄ src/
+```
+
+**Changes:** Deleted `Dockerfile.monitor` from `apps/payment-service/`
+
+**Analyzer Output:**
+
+```json
+{
+  "apps": {
+    "updated": [
+      {
+        "path": "apps/payment-service",
+        "app_name": "payment-service",
+        "app_config": "apps/payment-service/app.yaml"
+      }
+    ],
+    "all": [
+      {
+        "path": "apps/payment-service",
+        "app_name": "payment-service",
+        "app_config": "apps/payment-service/app.yaml"
+      }
+    ],
+    "deleted": [],
+    "has_updates": true,
+    "has_deletions": false
+  },
+  "containers": {
+    "updated": [
+      {
+        "path": "apps/payment-service",
+        "app_name": "payment-service",
+        "container_name": "payment-service",
+        "context": "apps/payment-service",
+        "dockerfile": {
+          "path": "apps/payment-service/Dockerfile",
+          "name": "Dockerfile",
+          "suffix": ""
+        }
+      }
+    ],
+    "all": [
+      {
+        "path": "apps/payment-service",
+        "app_name": "payment-service",
+        "container_name": "payment-service",
+        "context": "apps/payment-service",
+        "dockerfile": {
+          "path": "apps/payment-service/Dockerfile",
+          "name": "Dockerfile",
+          "suffix": ""
+        }
+      }
+    ],
+    "deleted": [
+      {
+        "app_name": "payment-service",
+        "container_name": "payment-service-monitor",
+        "context": "apps/payment-service",
+        "dockerfile": "apps/payment-service/Dockerfile.monitor"
+      }
+    ],
+    "has_updates": true,
+    "has_deletions": true
+  },
+  "ref": "HEAD~1"
+}
+```
+
+## Scenario 4: Deleted App (app.yaml removed)
+
+**Repository structure:**
+
+```
+apps/
+‚îî‚îÄ‚îÄ legacy-service/
+    ‚îú‚îÄ‚îÄ Dockerfile
+    ‚îî‚îÄ‚îÄ src/
+```
+
+**Changes:** Deleted `app.yaml` from `apps/legacy-service/`
+
+**Analyzer Output:**
+
+```json
+{
+  "apps": {
+    "updated": [],
+    "all": [],
+    "deleted": [
+      {
+        "path": "apps/legacy-service",
+        "app_name": "legacy-service",
+        "app_config": "apps/legacy-service/app.yaml",
+        "commit_sha": "abc123def456789test0commit0sha0for0testing"
+      }
+    ],
+    "has_updates": false,
+    "has_deletions": true
+  },
+  "containers": {
+    "updated": [],
+    "all": [
+      {
+        "path": "apps/legacy-service",
+        "app_name": "legacy-service",
+        "container_name": "legacy-service",
+        "context": "apps/legacy-service",
+        "dockerfile": {
+          "path": "apps/legacy-service/Dockerfile",
+          "name": "Dockerfile",
+          "suffix": ""
+        }
+      }
+    ],
+    "deleted": [],
+    "has_updates": false,
+    "has_deletions": false
+  },
+  "ref": "HEAD~1"
+}
+```
+
+## Scenario 5: Complete Folder Deletion
+
+**Changes:** Deleted entire `apps/old-service/` folder (which contained Dockerfile, app.yaml, and source files)
+
+**Analyzer Output:**
+
+```json
+{
+  "apps": {
+    "updated": [],
+    "all": [],
+    "deleted": [
+      {
+        "path": "apps/old-service",
+        "app_name": "old-service",
+        "app_config": "apps/old-service/app.yaml",
+        "commit_sha": "abc123def456789test0commit0sha0for0testing"
+      }
+    ],
+    "has_updates": false,
+    "has_deletions": true
+  },
+  "containers": {
+    "updated": [],
+    "all": [],
+    "deleted": [
+      {
+        "app_name": "old-service",
+        "container_name": "old-service",
+        "context": "apps/old-service",
+        "dockerfile": "apps/old-service/Dockerfile"
+      }
+    ],
+    "has_updates": false,
+    "has_deletions": true
+  },
+  "ref": "HEAD~1"
+}
+```
+
+## Scenario 6: Pre-built Images Only App
+
+**Repository structure:**
+
+```
+apps/
+‚îî‚îÄ‚îÄ monitoring-stack/
+    ‚îî‚îÄ‚îÄ app.yaml  # No Dockerfiles, only pre-built images
+```
+
+**Changes:** Modified `app.yaml` in `apps/monitoring-stack/`
+
+**Analyzer Output:**
+
+```json
+{
+  "apps": {
+    "updated": [
+      {
+        "path": "apps/monitoring-stack",
+        "app_name": "monitoring-stack",
+        "app_config": "apps/monitoring-stack/app.yaml"
+      }
+    ],
+    "all": [
+      {
+        "path": "apps/monitoring-stack",
+        "app_name": "monitoring-stack",
+        "app_config": "apps/monitoring-stack/app.yaml"
+      }
+    ],
+    "deleted": [],
+    "has_updates": true,
+    "has_deletions": false
+  },
+  "containers": {
+    "updated": [],
+    "all": [],
+    "deleted": [],
+    "has_updates": false,
+    "has_deletions": false
+  },
+  "ref": "origin/main"
+}
+```
+
+## Scenario 7: Mixed Changes and Deletions
+
+**Changes:**
+
+- Modified files in `apps/api/`
+- Deleted `Dockerfile.cache` from `apps/api/`
+- Deleted entire `apps/deprecated/` folder
+- Added new `apps/new-service/`
+
+**Analyzer Output:**
+
+```json
+{
+  "apps": {
+    "updated": [
+      { "path": "apps/api", "app_name": "api", "app_config": "apps/api/app.yaml" },
+      {
+        "path": "apps/new-service",
+        "app_name": "new-service",
+        "app_config": "apps/new-service/app.yaml"
+      }
+    ],
+    "all": [
+      { "path": "apps/api", "app_name": "api", "app_config": "apps/api/app.yaml" },
+      {
+        "path": "apps/new-service",
+        "app_name": "new-service",
+        "app_config": "apps/new-service/app.yaml"
+      }
+    ],
+    "deleted": [
+      {
+        "path": "apps/deprecated",
+        "app_name": "deprecated",
+        "app_config": "apps/deprecated/app.yaml",
+        "commit_sha": "abc123def456789test0commit0sha0for0testing"
+      }
+    ],
+    "has_updates": true,
+    "has_deletions": true
+  },
+  "containers": {
+    "updated": [
+      {
+        "path": "apps/api",
+        "app_name": "api",
+        "container_name": "api",
+        "context": "apps/api",
+        "dockerfile": {
+          "path": "apps/api/Dockerfile",
+          "name": "Dockerfile",
+          "suffix": ""
+        }
+      }
+    ],
+    "all": [
+      {
+        "path": "apps/api",
+        "app_name": "api",
+        "container_name": "api",
+        "context": "apps/api",
+        "dockerfile": {
+          "path": "apps/api/Dockerfile",
+          "name": "Dockerfile",
+          "suffix": ""
+        }
+      },
+      {
+        "path": "apps/new-service",
+        "app_name": "new-service",
+        "container_name": "new-service",
+        "context": "apps/new-service",
+        "dockerfile": {
+          "path": "apps/new-service/Dockerfile",
+          "name": "Dockerfile",
+          "suffix": ""
+        }
+      }
+    ],
+    "deleted": [
+      {
+        "app_name": "api",
+        "container_name": "api-cache",
+        "context": "apps/api",
+        "dockerfile": "apps/api/Dockerfile.cache"
+      },
+      {
+        "app_name": "deprecated",
+        "container_name": "deprecated",
+        "context": "apps/deprecated",
+        "dockerfile": "apps/deprecated/Dockerfile"
+      }
+    ],
+    "has_updates": true,
+    "has_deletions": true
+  },
+  "ref": "HEAD~1"
+}
+```
+
+## Scenario 8: Pull Request
+
+**Context:** Pull request from `feature/update-auth` to `main`
+
+**Analyzer Output:**
+
+```json
+{
+  "apps": {
+    "updated": [{ "path": "apps/auth", "app_name": "auth", "app_config": "apps/auth/app.yaml" }],
+    "all": [{ "path": "apps/auth", "app_name": "auth", "app_config": "apps/auth/app.yaml" }],
+    "deleted": [],
+    "has_updates": true,
+    "has_deletions": false
+  },
+  "containers": {
+    "updated": [
+      {
+        "path": "apps/auth",
+        "app_name": "auth",
+        "container_name": "auth",
+        "context": "apps/auth",
+        "dockerfile": {
+          "path": "apps/auth/Dockerfile",
+          "name": "Dockerfile",
+          "suffix": ""
+        }
+      }
+    ],
+    "all": [
+      {
+        "path": "apps/auth",
+        "app_name": "auth",
+        "container_name": "auth",
+        "context": "apps/auth",
+        "dockerfile": {
+          "path": "apps/auth/Dockerfile",
+          "name": "Dockerfile",
+          "suffix": ""
+        }
+      }
+    ],
+    "deleted": [],
+    "has_updates": true,
+    "has_deletions": false
+  },
+  "ref": "origin/main"
+}
+```
+
+## Scenario 9: Workflow Dispatch (Manual Trigger)
+
+**Context:** Manual workflow trigger - all apps should be available regardless of changes
+
+**Analyzer Output:**
+
+```json
+{
+  "apps": {
+    "updated": [],
+    "all": [
+      { "path": "apps/web-api", "app_name": "web-api", "app_config": "apps/web-api/app.yaml" },
+      { "path": "apps/frontend", "app_name": "frontend", "app_config": null }
+    ],
+    "deleted": [],
+    "has_updates": false,
+    "has_deletions": false
+  },
+  "containers": {
+    "updated": [],
+    "all": [
+      {
+        "path": "apps/web-api",
+        "app_name": "web-api",
+        "container_name": "web-api",
+        "context": "apps/web-api",
+        "dockerfile": {
+          "path": "apps/web-api/Dockerfile",
+          "name": "Dockerfile",
+          "suffix": ""
+        }
+      },
+      {
+        "path": "apps/frontend",
+        "app_name": "frontend",
+        "container_name": "frontend",
+        "context": "apps/frontend",
+        "dockerfile": {
+          "path": "apps/frontend/Dockerfile",
+          "name": "Dockerfile",
+          "suffix": ""
+        }
+      }
+    ],
+    "deleted": [],
+    "has_updates": false,
+    "has_deletions": false
+  },
+  "ref": ""
+}
+```
+
+## Usage in GitHub Actions
+
+### Building Changed Apps
+
+```yaml
+jobs:
+  analyze:
+    runs-on: ubuntu-latest
+    outputs:
+      matrix: ${{ steps.analyze.outputs.matrix }}
+      ref: ${{ steps.analyze.outputs.ref }}
+    steps:
+      - uses: actions/checkout@v3
+        with:
+          fetch-depth: 0
+
+      - name: Analyze Build Scope
+        id: analyze
+        uses: your-org/build-scope-analyzer@v2
+
+  build:
+    needs: analyze
+    if: fromJson(needs.analyze.outputs.matrix).apps.has_updates == true || fromJson(needs.analyze.outputs.matrix).containers.has_updates == true
+    strategy:
+      matrix:
+        app: ${{ fromJson(needs.analyze.outputs.matrix).apps.updated }}
+    steps:
+      - name: Build App
+        run: |
+          echo "Building app: ${{ matrix.app.app_name }}"
+          echo "Path: ${{ matrix.app.path }}"
+          echo "Config: ${{ matrix.app.app_config }}"
+
+  build_containers:
+    needs: analyze
+    if: fromJson(needs.analyze.outputs.matrix).containers.has_updates == true
+    strategy:
+      matrix:
+        container: ${{ fromJson(needs.analyze.outputs.matrix).containers.updated }}
+    steps:
+      - name: Build Container
+        run: |
+          echo "Building container for: ${{ matrix.container.app_name }}"
+          echo "Using Dockerfile: ${{ matrix.container.dockerfile.path }}"
+```
+
+### Building All Apps (for workflow_dispatch)
+
+```yaml
+jobs:
+  analyze:
+    runs-on: ubuntu-latest
+    outputs:
+      matrix: ${{ steps.analyze.outputs.matrix }}
+      ref: ${{ steps.analyze.outputs.ref }}
+    steps:
+      # ...same as above
+
+  build:
+    needs: analyze
+    strategy:
+      matrix:
+        app: ${{ fromJson(needs.analyze.outputs.matrix).apps.all }}
+    steps:
+      - name: Build App
+        run: |
+          echo "Building app: ${{ matrix.app.app_name }}"
+```
+
+### Cleaning Up Deleted Apps
+
+```yaml
+jobs:
+  cleanup_apps:
+    needs: analyze
+    if: fromJson(needs.analyze.outputs.matrix).apps.has_deletions == true
+    runs-on: ubuntu-latest
+    strategy:
+      matrix:
+        app: ${{ fromJson(needs.analyze.outputs.matrix).apps.deleted }}
+    steps:
+      - name: Destroy Container App
+        run: |
+          echo "Destroying app: ${{ matrix.app.app_name }}"
+          echo "Path: ${{ matrix.app.path }}"
+          echo "App config: ${{ matrix.app.app_config }}"
+          echo "Commit SHA: ${{ matrix.app.commit_sha }}"
+```
+
+### Cleaning Up Deleted Container Images
+
+```yaml
+jobs:
+  cleanup_containers:
+    needs: analyze
+    if: fromJson(needs.analyze.outputs.matrix).containers.has_deletions == true
+    runs-on: ubuntu-latest
+    strategy:
+      matrix:
+        container: ${{ fromJson(needs.analyze.outputs.matrix).containers.deleted }}
+    steps:
+      - name: Delete from ACR
+        run: |
+          echo "Deleting container image: ${{ matrix.container.image_name }}"
+          echo "From app: ${{ matrix.container.app_name }}"
+```
+
+### Job Dependency Order
+
+```yaml
+jobs:
+  analyze:
+    # ... analyze build scope
+
+  cleanup_apps:
+    needs: analyze
+    if: fromJson(needs.analyze.outputs.matrix).apps.has_deletions == true
+    # ... cleanup app steps
+
+  cleanup_containers:
+    needs: analyze
+    if: fromJson(needs.analyze.outputs.matrix).containers.has_deletions == true
+    # ... cleanup container steps
+
+  build:
+    needs: [analyze, cleanup_apps, cleanup_containers]
+    if: fromJson(needs.analyze.outputs.matrix).apps.has_updates == true
+    # ... build steps
+
+  deploy:
+    needs: [build]
+    # ... deploy steps
+```
+
+## Output Reference
+
+### Core Outputs
+
+| Output   | Type   | Description                                                |
+| -------- | ------ | ---------------------------------------------------------- |
+| `matrix` | JSON   | Contains all app and container data in a structured format |
+| `ref`    | String | Git reference used for comparison                          |
+
+### Matrix Structure
+
+The `matrix` output contains a JSON object with the following structure:
+
+```typescript
+interface Matrix {
+  apps: {
+    updated: AppItem[];
+    all: AppItem[];
+    deleted: DeletedApp[];
+    has_updates: boolean;
+    has_deletions: boolean;
+  };
+  containers: {
+    updated: ContainerItem[];
+    all: ContainerItem[];
+    deleted: DeletedContainer[];
+    has_updates: boolean;
+    has_deletions: boolean;
+  };
+  ref: string;
+}
+```
+
+### App Item Structure
+
+```typescript
+interface AppItem {
+  path: string; // Relative path to app folder
+  app_name: string; // App name (from config or folder)
+  app_config: string | null; // Path to app.yaml/app.yml (null if not found)
+}
+```
+
+### Container Item Structure
+
+```typescript
+interface ContainerItem {
+  path: string; // Relative path to app folder
+  app_name: string; // App name (from config or folder)
+  container_name: string; // Container name (from config or Dockerfile)
+  context: string; // Docker build context (from # @context: ... or folder)
+  dockerfile: {
+    path: string; // Path to Dockerfile
+    name: string; // Dockerfile name
+    suffix: string; // Suffix (e.g., .auth, .logger)
+  };
+}
+```
+
+### Deleted Container Structure
+
+```typescript
+interface DeletedContainer {
+  app_name: string; // App name
+  container_name: string; // Container name
+  context: string; // Docker build context
+  dockerfile: string; // Path to Dockerfile
+  commit_sha: string; // Commit SHA of the version with this container
+}
+```
+
+### Deleted App Structure
+
+```typescript
+interface DeletedApp {
+  path: string; // Relative path to app folder
+  app_name: string; // App name
+  app_config: string; // Path to app.yaml/app.yml
+  commit_sha: string; // Commit SHA of the version with this app
+}
+```
+
+---
+
+**Note:** All containers now include `container_name` and `context` fields. Deleted containers also include these fields for robust cleanup and traceability.
diff --git a/build-scope-analyzer/example-workflow.yml b/build-scope-analyzer/example-workflow.yml
new file mode 100644
index 0000000..ff443a6
--- /dev/null
+++ b/build-scope-analyzer/example-workflow.yml
@@ -0,0 +1,137 @@
+name: Build and Deploy Apps
+
+on:
+  push:
+    branches: [main]
+  pull_request:
+    branches: [main]
+  workflow_dispatch:
+    inputs:
+      build_all:
+        description: "Build all apps regardless of changes"
+        required: false
+        default: "false"
+        type: boolean
+
+jobs:
+  analyze:
+    name: Analyze Changes
+    runs-on: ubuntu-latest
+    outputs:
+      matrix: ${{ steps.scope.outputs.matrix }}
+      ref: ${{ steps.scope.outputs.ref }}
+    steps:
+      - uses: actions/checkout@v4
+        with:
+          fetch-depth: 0
+
+      - name: Analyze changes
+        id: scope
+        uses: HafslundEcoVannkraft/stratus-actions/build-scope-analyzer@v3
+        with:
+          root-path: ${{ github.workspace }}
+          include-pattern: "apps/*"
+          # Optional: exclude-pattern: 'tests/*'
+
+  build-apps:
+    name: Build ${{ matrix.app.app_name }}
+    needs: analyze
+    if: |
+      (github.event_name != 'workflow_dispatch' && fromJson(needs.analyze.outputs.matrix).apps.has_updates == true) ||
+      (github.event_name == 'workflow_dispatch' && inputs.build_all == true)
+    runs-on: ubuntu-latest
+    strategy:
+      matrix:
+        app: ${{ github.event_name == 'workflow_dispatch' && inputs.build_all == true && fromJson(needs.analyze.outputs.matrix).apps.all || fromJson(needs.analyze.outputs.matrix).apps.updated }}
+    steps:
+      - uses: actions/checkout@v4
+
+      - name: Build App
+        run: |
+          echo "Building app: ${{ matrix.app.app_name }}"
+          echo "App path: ${{ matrix.app.path }}"
+          echo "App config: ${{ matrix.app.app_config }}"
+          # Add your app build logic here
+
+      - name: Deploy Container App
+        if: matrix.app.app_config != null
+        run: |
+          echo "Deploying ${{ matrix.app.app_name }} with config: ${{ matrix.app.app_config }}"
+          # Add your deployment logic here
+
+  build-containers:
+    name: Build Container ${{ matrix.container.container_name }}
+    needs: analyze
+    if: |
+      (github.event_name != 'workflow_dispatch' && fromJson(needs.analyze.outputs.matrix).containers.has_updates == true) ||
+      (github.event_name == 'workflow_dispatch' && inputs.build_all == true)
+    runs-on: ubuntu-latest
+    strategy:
+      matrix:
+        container: ${{ github.event_name == 'workflow_dispatch' && inputs.build_all == true && fromJson(needs.analyze.outputs.matrix).containers.all || fromJson(needs.analyze.outputs.matrix).containers.updated }}
+    steps:
+      - uses: actions/checkout@v4
+
+      - name: Build Container
+        run: |
+          echo "Building container: ${{ matrix.container.container_name }}"
+          echo "App name: ${{ matrix.container.app_name }}"
+          echo "Context: ${{ matrix.container.context }}"
+          echo "Dockerfile: ${{ matrix.container.dockerfile.path }}"
+          # Example Docker build command:
+          # docker build -f ${{ matrix.container.dockerfile.path }} -t ${{ matrix.container.container_name }} ${{ matrix.container.context }}
+
+  cleanup-deleted-apps:
+    name: Cleanup Deleted Apps
+    needs: analyze
+    if: fromJson(needs.analyze.outputs.matrix).apps.has_deletions == true
+    runs-on: ubuntu-latest
+    strategy:
+      matrix:
+        app: ${{ fromJson(needs.analyze.outputs.matrix).apps.deleted }}
+    steps:
+      - name: Destroy Container App
+        run: |
+          echo "Destroying app: ${{ matrix.app.app_name }}"
+          echo "Path: ${{ matrix.app.path }}"
+          echo "App config: ${{ matrix.app.app_config }}"
+          echo "Commit SHA: ${{ matrix.app.commit_sha }}"
+          # Add your cleanup logic here
+
+  cleanup-deleted-containers:
+    name: Cleanup Deleted Container Images
+    needs: analyze
+    if: fromJson(needs.analyze.outputs.matrix).containers.has_deletions == true
+    runs-on: ubuntu-latest
+    strategy:
+      matrix:
+        container: ${{ fromJson(needs.analyze.outputs.matrix).containers.deleted }}
+    steps:
+      - name: Delete from Container Registry
+        run: |
+          echo "Deleting container: ${{ matrix.container.container_name }}"
+          echo "From app: ${{ matrix.container.app_name }}"
+          echo "Context: ${{ matrix.container.context }}"
+          echo "Original Dockerfile: ${{ matrix.container.dockerfile }}"
+          echo "Commit SHA: ${{ matrix.container.commit_sha }}"
+          # Add your ACR cleanup logic here
+
+  summary:
+    name: Summary
+    needs: [analyze, build-apps, build-containers, cleanup-deleted-apps, cleanup-deleted-containers]
+    if: always()
+    runs-on: ubuntu-latest
+    steps:
+      - name: Print Summary
+        run: |
+          echo "## Build Scope Analysis Summary"
+          echo "- Apps built: ${{ needs.build-apps.result == 'success' && 'Yes' || 'No' }}"
+          echo "- Containers built: ${{ needs.build-containers.result == 'success' && 'Yes' || 'No' }}"
+          echo "- Apps cleaned up: ${{ needs.cleanup-deleted-apps.result == 'success' && 'Yes' || 'No' }}"
+          echo "- Containers cleaned up: ${{ needs.cleanup-deleted-containers.result == 'success' && 'Yes' || 'No' }}"
+
+# Notes:
+# - All container and app properties are now accessed via fromJson(matrix) and use the new output structure.
+# - Use matrix.container.container_name, matrix.container.context, etc. for all container jobs.
+# - Use matrix.app.app_name, matrix.app.path, etc. for all app jobs.
+# - Deleted containers include container_name, context, and dockerfile for robust cleanup.
diff --git a/build-scope-analyzer/main.py b/build-scope-analyzer/main.py
new file mode 100644
index 0000000..0bde9d5
--- /dev/null
+++ b/build-scope-analyzer/main.py
@@ -0,0 +1,666 @@
+#!/usr/bin/env python3
+"""
+Build Scope Analyzer V3 - Enhanced deletion tracking
+
+This script analyzes git diff to identify what needs to be built and what was deleted.
+It provides detailed deletion information for proper cleanup in CI/CD pipelines.
+"""
+
+import os
+import sys
+import json
+import subprocess
+import argparse
+import fnmatch
+import yaml
+import logging
+from pathlib import Path
+from typing import List, Dict, Set, Optional, Tuple, Any
+
+
+class BuildScopeAnalyzer:
+    """Analyzes git changes and generates strategy matrix output"""
+
+    def __init__(self, root_path: str, include_pattern: str = '', exclude_pattern: str = '', mock_git: bool = False):
+        self.root_path = Path(root_path).resolve()
+        self.include_pattern = include_pattern
+        self.exclude_pattern = exclude_pattern
+        self.changed_files: Set[Path] = set()
+        self.deleted_files: Set[Path] = set()
+        self.renamed_files: Dict[Path, Path] = {}  # old_path -> new_path
+        self.mock_git = mock_git  # Flag to enable mock mode for local testing
+
+    def run_git_command(self, cmd: List[str]) -> str:
+        """Execute a git command and return output"""
+        if self.mock_git:
+            # When in mock mode, return predefined mock data for common git commands
+            cmd_str = " ".join(cmd)
+            if "rev-parse" in cmd_str:
+                return "mock-sha-12345"
+            if "diff --name-status" in cmd_str:
+                # Return some mock changed files for testing
+                mock_files = [
+                    f"M\t{self.root_path / 'app1/app.yaml'}",
+                    f"A\t{self.root_path / 'app2/app.yaml'}",
+                    f"D\t{self.root_path / 'app3/app.yaml'}",
+                    f"M\t{self.root_path / 'app1/Dockerfile'}",
+                    f"A\t{self.root_path / 'app2/Dockerfile'}"
+                ]
+                return "\n".join(mock_files)
+            # Default mock response
+            return ""
+
+        try:
+            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
+            return result.stdout.strip()
+        except subprocess.CalledProcessError as e:
+            logging.error(f"Git command failed: {' '.join(cmd)}")
+            logging.error(f"Error: {e.stderr}")
+            sys.exit(1)
+
+    def get_event_type(self) -> str:
+        """Get GitHub event type from environment"""
+        return os.environ.get('GITHUB_EVENT_NAME', 'push')
+
+    def get_comparison_ref(self) -> Tuple[str, Optional[str]]:
+        """Determine the reference to compare against and resolve its commit SHA
+
+        Returns:
+            Tuple containing:
+                - ref_name: String with the reference name (e.g., "HEAD~1", "origin/main")
+                - commit_sha: String with the resolved commit SHA, or None if no ref
+        """
+        event_type = self.get_event_type()
+
+        if event_type == 'pull_request':
+            # For PRs, compare against the base branch
+            base_ref = os.environ.get('GITHUB_BASE_REF', 'main')
+            ref_name = f"origin/{base_ref}"
+            try:
+                # Resolve the commit SHA
+                commit_sha = self.run_git_command(['git', 'rev-parse', ref_name])
+                return ref_name, commit_sha
+            except:
+                return ref_name, None
+        elif event_type == 'workflow_dispatch':
+            # For workflow_dispatch, we don't need to compare against anything
+            # since we'll use all_apps output anyway
+            return "", None
+        else:
+            # For push events, compare against previous commit
+            ref_name = "HEAD~1"
+            try:
+                # Resolve the commit SHA
+                commit_sha = self.run_git_command(['git', 'rev-parse', ref_name])
+                return ref_name, commit_sha
+            except:
+                return ref_name, None
+
+    def get_changed_files(self) -> Tuple[Set[Path], Set[Path], Dict[Path, Path]]:
+        """Get list of changed, deleted, and renamed files from git diff"""
+        ref_name, commit_sha = self.get_comparison_ref()
+
+        # If ref is empty (workflow_dispatch), return empty sets
+        if not ref_name:
+            return set(), set(), {}
+
+        # Get all changes with status
+        diff_output = self.run_git_command(['git', 'diff', '--name-status', ref_name])
+
+        changed = set()
+        deleted = set()
+        renamed = {}
+
+        for line in diff_output.splitlines():
+            if not line:
+                continue
+
+            parts = line.split('\t')
+            if len(parts) < 2:
+                continue
+
+            status = parts[0]
+
+            if status == 'D':  # Deleted
+                deleted.add(Path(parts[1]))
+            elif status == 'R':  # Renamed
+                if len(parts) >= 3:
+                    old_path = Path(parts[1])
+                    new_path = Path(parts[2])
+                    renamed[old_path] = new_path
+                    changed.add(new_path)
+            elif status in ['A', 'M']:  # Added or Modified
+                changed.add(Path(parts[1]))
+
+        return changed, deleted, renamed
+
+    def should_include_path(self, path: Path) -> bool:
+        """Check if path should be included based on patterns"""
+        path_str = str(path)
+
+        # First check include pattern if specified
+        if self.include_pattern:
+            if not fnmatch.fnmatch(path_str, self.include_pattern):
+                return False
+
+        # Then check exclude pattern if specified
+        if self.exclude_pattern:
+            if fnmatch.fnmatch(path_str, self.exclude_pattern):
+                return False
+
+        return True
+
+    def find_dockerfiles(self, folder: Path) -> List[Dict[str, str]]:
+        """Find all Dockerfiles in a folder and return info about them"""
+        dockerfiles = []
+        full_folder = self.root_path / folder
+
+        # Look for all files starting with "Dockerfile"
+        for file in full_folder.glob("Dockerfile*"):
+            if file.is_file():
+                dockerfile_info = {
+                    'path': str(folder / file.name),
+                    'name': file.name
+                }
+
+                # Determine the container name based on Dockerfile name
+                if file.name == "Dockerfile":
+                    dockerfile_info['suffix'] = ''
+                else:
+                    # Extract suffix (e.g., "sidecar" from "Dockerfile.sidecar")
+                    dockerfile_info['suffix'] = file.name.replace("Dockerfile.", "")
+
+                dockerfiles.append(dockerfile_info)
+
+        return dockerfiles
+
+    def find_app_yaml(self, folder: Path) -> Optional[str]:
+        """Check if app.yaml or app.yml exists in folder"""
+        full_folder = self.root_path / folder
+
+        for config_name in ['app.yaml', 'app.yml']:
+            config_path = full_folder / config_name
+            if config_path.exists():
+                return str(folder / config_name)
+
+        return None
+
+    def analyze_deletions(self) -> Dict[str, Any]:
+        """Analyze deleted files to determine what cleanup is needed"""
+        deletions = {
+            'apps': [],  # Apps that need terraform destroy
+            'containers': [],  # Container images that need ACR cleanup
+        }
+
+        # Group deletions by folder
+        deleted_by_folder: Dict[Path, Dict[str, List[Path]]] = {}
+
+        for file_path in self.deleted_files:
+            if not self.should_include_path(file_path):
+                continue
+
+            folder = file_path.parent
+            if folder not in deleted_by_folder:
+                deleted_by_folder[folder] = {
+                    'dockerfiles': [],
+                    'app_configs': [],
+                    'other_files': []
+                }
+
+            filename = file_path.name
+            if filename.startswith('Dockerfile'):
+                deleted_by_folder[folder]['dockerfiles'].append(file_path)
+            elif filename in ['app.yaml', 'app.yml']:
+                deleted_by_folder[folder]['app_configs'].append(file_path)
+            else:
+                deleted_by_folder[folder]['other_files'].append(file_path)
+
+        # Process deletions
+        for folder_path, deleted_items in deleted_by_folder.items():
+            app_name = folder_path.name
+
+            # Check if the folder itself was deleted
+            if not (self.root_path / folder_path).exists():
+                # Folder was deleted - add to deleted_apps
+                # For consistent structure with apps.all and apps.updated, construct the expected app.yaml path
+                yaml_path = str(folder_path / 'app.yaml')  # Default to app.yaml path
+                # Check if we had app.yaml or app.yml in the deleted files
+                for app_config in deleted_items['app_configs']:
+                    yaml_path = str(app_config)
+                    break
+
+                deletions['apps'].append({
+                    'path': str(folder_path),
+                    'app_name': app_name,
+                    'app_config': yaml_path
+                })
+
+                # Also need to determine what containers were in this folder
+                # Since the folder is gone, we need to infer from deleted files
+                for dockerfile in deleted_items['dockerfiles']:
+                    dockerfile_name = dockerfile.name
+                    # Create a dockerfile dict similar to what other methods use
+                    dockerfile_dict = {'name': dockerfile_name}
+                    if dockerfile_name == 'Dockerfile':
+                        dockerfile_dict['suffix'] = ''
+                    else:
+                        dockerfile_dict['suffix'] = dockerfile_name.replace('Dockerfile.', '')
+
+                    # Try to find app.yaml/app.yml in the deleted files to get app name
+                    app_config_path = None
+                    for app_config in deleted_items['app_configs']:
+                        app_config_path = str(app_config)
+                        break
+
+                    # Use our standard method for consistent container naming
+                    container_name = self.get_container_name(app_name, dockerfile_dict, app_config_path)
+
+                    deletions['containers'].append({
+                        'app_name': app_name,
+                        'container_name': container_name,
+                        'dockerfile': str(dockerfile)
+                    })
+            else:
+                # Folder still exists - handle partial deletions
+                # If app.yaml was deleted, the app needs to be destroyed
+                if deleted_items['app_configs']:
+                    deletions['apps'].append({
+                        'path': str(folder_path),
+                        'app_name': app_name,
+                        'app_config': str(deleted_items['app_configs'][0])  # Consistent with apps.all and apps.updated
+                    })
+
+                # Track deleted containers (Dockerfiles)
+                for dockerfile in deleted_items['dockerfiles']:
+                    dockerfile_name = dockerfile.name
+                    # Create a dockerfile dict similar to what other methods use
+                    dockerfile_dict = {'name': dockerfile_name}
+                    if dockerfile_name == 'Dockerfile':
+                        dockerfile_dict['suffix'] = ''
+                    else:
+                        dockerfile_dict['suffix'] = dockerfile_name.replace('Dockerfile.', '')
+
+                    # Find app.yaml or app.yml in the deleted files
+                    app_config_path = None
+                    for app_config in deleted_items['app_configs']:
+                        app_config_path = str(app_config)
+                        break
+
+                    # If the folder wasn't deleted, check if app.yaml/app.yml still exists
+                    if not app_config_path:
+                        potential_app_yaml = self.find_app_yaml(folder_path)
+                        if potential_app_yaml:
+                            app_config_path = potential_app_yaml
+
+                    # Use our standard method for consistent container naming
+                    container_name = self.get_container_name(app_name, dockerfile_dict, app_config_path)
+
+                    deletions['containers'].append({
+                        'app_name': app_name,
+                        'container_name': container_name,
+                        'dockerfile': str(dockerfile)
+                    })
+
+        return deletions
+
+    def analyze_folder(self, folder: Path, changed_files: Set[Path]) -> Optional[Dict]:
+        """Analyze a folder for Dockerfiles and optionally app configuration"""
+        dockerfiles = self.find_dockerfiles(folder)
+        app_config = self.find_app_yaml(folder)
+
+        # Only include folders with at least a Dockerfile or app.yaml/app.yml
+        if not app_config and not dockerfiles:
+            return None
+
+        # Use folder name as app name
+        app_name = folder.name
+
+        return {
+            'path': str(folder),
+            'app_name': app_name,
+            'app_config': app_config,  # Can be None
+            'dockerfiles': dockerfiles,  # Can be empty
+            'changed_files': [str(f) for f in changed_files]
+        }
+
+    def find_app_folders(self) -> Dict[str, Any]:
+        """Find folders containing changed files and analyze them"""
+        self.changed_files, self.deleted_files, self.renamed_files = self.get_changed_files()
+
+        # Group files by their parent directories
+        changed_folders: Dict[Path, Set[Path]] = {}
+
+        for file_path in self.changed_files:
+            if self.should_include_path(file_path):
+                folder = file_path.parent
+                if folder not in changed_folders:
+                    changed_folders[folder] = set()
+                changed_folders[folder].add(file_path)
+
+        # Analyze each folder
+        apps = {}
+        for folder, files in changed_folders.items():
+            app_info = self.analyze_folder(folder, files)
+            if app_info:
+                apps[folder] = app_info
+
+        # Get comparison ref and commit SHA
+        ref_name, commit_sha = self.get_comparison_ref()
+
+        # Analyze deletions
+        deletions = self.analyze_deletions()
+
+        return {
+            'apps': apps,
+            'deletions': deletions,
+            'ref': ref_name,
+            'commit_sha': commit_sha
+        }
+
+    def analyze_all_builds(self) -> List[Dict]:
+        """Analyze all apps in the include pattern, regardless of changes"""
+        all_apps = []
+
+        # If we have an include pattern like "apps/*", we need to find matching directories
+        if self.include_pattern:
+            # Convert glob pattern to find directories
+            # For pattern like "apps/*", we want to find all direct subdirectories of "apps"
+            pattern_parts = self.include_pattern.split('/')
+
+            if '*' in pattern_parts[-1]:
+                # Pattern ends with *, so we want directories at this level
+                parent_path = '/'.join(pattern_parts[:-1]) if len(pattern_parts) > 1 else '.'
+                parent_dir = self.root_path / parent_path
+
+                if parent_dir.exists() and parent_dir.is_dir():
+                    # Find all subdirectories
+                    for path in parent_dir.iterdir():
+                        if path.is_dir():
+                            relative_path = path.relative_to(self.root_path)
+                            if self.should_include_path(relative_path):
+                                app_info = self.analyze_folder(relative_path, set())
+                                if app_info:
+                                    # Use the same structure as the main matrix
+                                    item = {
+                                        'path': app_info['path'],
+                                        'app_name': app_info['app_name'],
+                                        'dockerfiles': app_info['dockerfiles']
+                                    }
+                                    if app_info['app_config']:
+                                        item['app_config'] = app_info['app_config']
+                                    all_apps.append(item)
+            else:
+                # Pattern is a specific directory
+                specific_dir = self.root_path / self.include_pattern
+                if specific_dir.exists() and specific_dir.is_dir():
+                    relative_path = specific_dir.relative_to(self.root_path)
+                    app_info = self.analyze_folder(relative_path, set())
+                    if app_info:
+                        # Use the same structure as the main matrix
+                        item = {
+                            'path': app_info['path'],
+                            'app_name': app_info['app_name'],
+                            'dockerfiles': app_info['dockerfiles']
+                        }
+                        if app_info['app_config']:
+                            item['app_config'] = app_info['app_config']
+                        all_apps.append(item)
+        else:
+            # No include pattern, check all directories at root level
+            for path in self.root_path.iterdir():
+                if path.is_dir() and not path.name.startswith('.'):
+                    relative_path = path.relative_to(self.root_path)
+                    if self.should_include_path(relative_path):
+                        app_info = self.analyze_folder(relative_path, set())
+                        if app_info:
+                            # Use the same structure as the main matrix
+                            item = {
+                                'path': app_info['path'],
+                                'app_name': app_info['app_name'],
+                                'dockerfiles': app_info['dockerfiles']
+                            }
+                            if app_info['app_config']:
+                                item['app_config'] = app_info['app_config']
+                            all_apps.append(item)
+
+        return all_apps
+
+    def generate_matrix_output(self) -> Dict:
+        """Generate output suitable for GitHub Actions matrix"""
+        analysis = self.find_app_folders()
+        changed_files = self.changed_files
+        renamed_files = self.renamed_files
+
+        # Helper to check if a folder is only renamed (no real file changes)
+        def is_only_renamed(folder: Path) -> bool:
+            # If all files in this folder are only in renamed_files, and not in changed_files
+            for old, new in renamed_files.items():
+                if new.parent == folder or old.parent == folder:
+                    # If the file is not in changed_files, it's only renamed
+                    if new not in changed_files and old not in changed_files:
+                        continue
+                    else:
+                        return False
+            return True if renamed_files else False
+
+        # Process changed apps
+        updated_apps = []  # Folders with app.yaml/app.yml
+        container_items = []  # Folders with Dockerfiles
+
+        for folder, app_info in analysis['apps'].items():
+            folder_path = Path(app_info['path'])
+            # Only include if any file in folder or subfolders is changed and not just renamed
+            if app_info['app_config']:
+                if self.folder_has_changes(folder_path, changed_files) and not is_only_renamed(folder_path):
+                    app_item = {
+                        'path': app_info['path'],
+                        'app_name': app_info['app_name'],
+                        'app_config': app_info['app_config']
+                    }
+                    updated_apps.append(app_item)
+
+            # Handle Dockerfiles (containers matrix)
+            if app_info['dockerfiles'] and len(app_info['dockerfiles']) > 0:
+                for dockerfile in app_info['dockerfiles']:
+                    if self.folder_has_changes(folder_path, changed_files) and not is_only_renamed(folder_path):
+                        container_name = self.get_container_name(app_info['app_name'], dockerfile, app_info['app_config'])
+                        context = self.get_dockerfile_context(dockerfile['path'], app_info['path'])
+                        suffix = dockerfile.get('suffix', '')
+                        container_item = {
+                            'path': app_info['path'],
+                            'context': context,
+                            'app_name': app_info['app_name'],
+                            'dockerfile': dockerfile,
+                            'container_name': container_name
+                        }
+                        container_items.append(container_item)
+
+        # Process all apps (for workflow_dispatch scenarios)
+        all_builds = self.analyze_all_builds()
+
+        # Split into app configs and containers
+        all_apps = []  # All folders with app.yaml/app.yml
+        all_containers = []  # All Dockerfiles
+
+        for app in all_builds:
+            if app.get('app_config'):
+                app_item = {
+                    'path': app['path'],
+                    'app_name': app['app_name'],
+                    'app_config': app['app_config']
+                }
+                all_apps.append(app_item)
+            if app.get('dockerfiles') and len(app['dockerfiles']) > 0:
+                for dockerfile in app['dockerfiles']:
+                    container_name = self.get_container_name(app['app_name'], dockerfile, app.get('app_config'))
+                    context = self.get_dockerfile_context(dockerfile['path'], app['path'])
+                    suffix = dockerfile.get('suffix', '')
+                    container_item = {
+                        'path': app['path'],
+                        'context': context,
+                        'app_name': app['app_name'],
+                        'dockerfile': dockerfile,
+                        'container_name': container_name
+                    }
+                    all_containers.append(container_item)
+
+        # Check if there are updated or deleted apps/containers
+        has_app_updates = len(updated_apps) > 0
+        has_app_deletions = len(analysis['deletions']['apps']) > 0
+        has_container_updates = len(container_items) > 0
+        has_container_deletions = len(analysis['deletions']['containers']) > 0
+
+        # Get the commit SHA for deleted items
+        commit_sha = analysis.get('commit_sha')
+
+        # Add commit SHA to each deleted app and container if available
+        deleted_apps = analysis['deletions']['apps']
+        deleted_containers = analysis['deletions']['containers']
+
+        if commit_sha:
+            # Add to deleted apps
+            for app in deleted_apps:
+                app['commit_sha'] = commit_sha
+
+            # Add to deleted containers
+            for container in deleted_containers:
+                container['commit_sha'] = commit_sha
+
+        # Create the clean, focused return object
+        return {
+            'apps': {
+                'updated': updated_apps,  # Folders with app.yaml/app.yml that changed
+                'all': all_apps,       # All folders with app.yaml/app.yml
+                'deleted': deleted_apps,  # Deleted app.yaml/app.yml files
+                'has_updates': has_app_updates,
+                'has_deletions': has_app_deletions
+            },
+            'containers': {
+                'updated': container_items,  # Changed Dockerfiles
+                'all': all_containers,       # All Dockerfiles
+                'deleted': analysis['deletions']['containers'],  # Deleted Dockerfiles
+                'has_updates': has_container_updates,
+                'has_deletions': has_container_deletions
+            },
+            'ref': analysis['ref']
+        }
+
+    def folder_has_changes(self, folder: Path, changed_files: Set[Path]) -> bool:
+        """Check if any file in folder or its subfolders is in changed_files"""
+        folder_abs = (self.root_path / folder).resolve()
+        for changed_file in changed_files:
+            changed_abs = (self.root_path / changed_file).resolve()
+            try:
+                changed_abs.relative_to(folder_abs)
+                return True
+            except ValueError:
+                continue
+        return False
+
+    def get_app_name_from_yaml(self, app_yaml_path: Optional[str]) -> Optional[str]:
+        """Extract the 'name' property from app.yaml/app.yml if present"""
+        if not app_yaml_path:
+            return None
+        try:
+            with open(self.root_path / app_yaml_path, 'r') as f:
+                data = yaml.safe_load(f)
+                if isinstance(data, dict) and 'name' in data:
+                    return str(data['name'])
+        except Exception:
+            pass
+        return None
+
+    def get_dockerfile_context(self, dockerfile_path: str, default_context: str) -> str:
+        """Read the Dockerfile and extract a custom context if specified via # @context: ..."""
+        try:
+            with open(self.root_path / dockerfile_path, 'r') as f:
+                for _ in range(10):
+                    line = f.readline()
+                    if not line:
+                        break
+                    if line.strip().startswith('# @context:'):
+                        return line.strip().split(':', 1)[1].strip()
+        except Exception:
+            pass
+        return default_context
+
+    def get_container_name(self, app_name: str, dockerfile: Dict[str, str], app_config: Optional[str] = None) -> str:
+        # Try to get name from app.yaml/app.yml first if available
+        base_name = self.get_app_name_from_yaml(app_config) or app_name
+        suffix = dockerfile.get('suffix', '')
+        container_name = base_name if not suffix else f"{base_name}-{suffix}"
+        # Ensure container name is lowercase for Azure Container Registry compatibility
+        return container_name.lower()
+
+def check_git_repository():
+    """Check if running inside a git repository (any subdirectory)."""
+    try:
+        subprocess.run(
+            ["git", "rev-parse", "--is-inside-work-tree"],
+            check=True,
+            stdout=subprocess.DEVNULL,
+            stderr=subprocess.DEVNULL,
+        )
+        logging.info("Git repository detected.")
+    except Exception:
+        logging.warning("Not inside a git repository.")
+        logging.warning("This container is designed to run in the context of a git repository.")
+        logging.warning("Results may not be as expected.")
+
+def main():
+    """Main entry point"""
+    # Configure logging to stderr, INFO level by default
+    logging.basicConfig(
+        level=logging.INFO,
+        format="%(levelname)s: %(message)s",
+        stream=sys.stderr
+    )
+
+    parser = argparse.ArgumentParser(description='Analyze git changes for build scope')
+    parser.add_argument('--root-path', default=os.environ.get('GITHUB_WORKSPACE', '.'),
+                        help='Root path to search for changes')
+    parser.add_argument('--include-pattern', help='Pattern for paths to include')
+    parser.add_argument('--exclude-pattern', help='Pattern for paths to exclude')
+    parser.add_argument('--ref', help='Git ref to compare against')
+    parser.add_argument('--output-format', choices=['json', 'github'], default='github',
+                        help='Output format')
+    parser.add_argument('--mock-git', action='store_true',
+                        help='Use mock git data for local testing without a git repo')
+
+    args = parser.parse_args()
+
+    # Change working directory to root_path for correct git context
+    os.chdir(args.root_path)
+
+    # Check if we're in a git repository (now in correct directory)
+    check_git_repository()
+
+    analyzer = BuildScopeAnalyzer(
+        root_path=args.root_path,
+        include_pattern=args.include_pattern,
+        exclude_pattern=args.exclude_pattern,
+        mock_git=args.mock_git
+    )
+
+    output = analyzer.generate_matrix_output()
+
+    if args.output_format == 'github':
+        # Output in GitHub Actions format
+        github_output = os.environ.get('GITHUB_OUTPUT')
+        if github_output:
+            with open(github_output, 'a') as f:
+                # Output the full matrix object
+                f.write(f"matrix={json.dumps(output)}\n")
+                # Output the reference information
+                f.write(f"ref={output['ref']}\n")
+        else:
+            # Fallback to console output for testing
+            print(f"matrix={json.dumps(output)}")
+            print(f"ref={output['ref']}")
+    else:
+        # Output as JSON
+        print(json.dumps(output, indent=2))
+
+
+if __name__ == '__main__':
+    main()
\ No newline at end of file
diff --git a/build-scope-analyzer/pyproject.toml b/build-scope-analyzer/pyproject.toml
new file mode 100644
index 0000000..dd44d24
--- /dev/null
+++ b/build-scope-analyzer/pyproject.toml
@@ -0,0 +1,22 @@
+# NOTE: requirements.txt exists only for Dependabot support. Keep dependencies in sync manually.
+# See https://github.com/dependabot/dependabot-core/issues/3608 for details.
+[build-system]
+requires = ["setuptools>=61.0", "wheel"]
+build-backend = "setuptools.build_meta"
+
+[project]
+name = "build-scope-analyzer"
+version = "3.1.10"
+description = "Analyze git changes to identify what needs to be built and generate strategy matrix"
+authors = [
+    {name = "Stratus Team"}
+]
+requires-python = ">=3.12"
+dependencies = [
+    "pyyaml>=6.0.1",
+]
+readme = "README.md"
+license = {text = "MIT"}
+
+[tool.setuptools]
+packages = []  # No packages, we're using the script directly
diff --git a/build-scope-analyzer/requirements.txt b/build-scope-analyzer/requirements.txt
new file mode 100644
index 0000000..c408dbc
--- /dev/null
+++ b/build-scope-analyzer/requirements.txt
@@ -0,0 +1,4 @@
+# This file is required for Dependabot support.
+# Keep this in sync with pyproject.toml dependencies manually.
+# See https://github.com/dependabot/dependabot-core/issues/3608 for details.
+pyyaml>=6.0.1
diff --git a/hello-world/README.md b/hello-world/README.md
new file mode 100644
index 0000000..13082bb
--- /dev/null
+++ b/hello-world/README.md
@@ -0,0 +1,85 @@
+# Hello World Composite Action
+
+A simple GitHub composite action that prints a hello world message. This action is part of our monorepo collection of reusable GitHub Actions.
+
+## Features
+
+- üöÄ Lightweight and fast execution
+- üîß Simple bash script implementation
+- üì¶ Easy to integrate into existing workflows
+- üéØ Perfect for testing and learning GitHub Actions
+
+## Usage
+
+```yaml
+name: Hello World Workflow
+
+on:
+  push:
+    branches:
+      - main
+  workflow_dispatch:
+
+jobs:
+  hello:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+
+      - name: Say Hello
+        uses: HafslundEcoVannkraft/stratus-actions/hello-world@v1
+```
+
+## Location in Monorepo
+
+```
+repository-root/
+‚îú‚îÄ‚îÄ hello-world/              # This action
+‚îÇ   ‚îú‚îÄ‚îÄ README.md
+‚îÇ   ‚îú‚îÄ‚îÄ action.yml
+‚îÇ   ‚îî‚îÄ‚îÄ entrypoint.sh
+‚îú‚îÄ‚îÄ release/                  # Release action
+‚îú‚îÄ‚îÄ build-scope-analyzer/     # Build scope analyzer action
+‚îî‚îÄ‚îÄ other-actions/            # Other composite actions
+```
+
+## File Permissions
+
+Make sure the entrypoint script has executable permissions:
+
+```bash
+git update-index --chmod=+x hello-world/entrypoint.sh
+```
+
+## Inputs
+
+This action doesn't require any inputs.
+
+## Outputs
+
+This action doesn't produce any outputs. It simply prints "Hello world from stratus-actions composite action" to the workflow logs.
+
+## Examples
+
+### Basic Usage
+
+```yaml
+- name: Say Hello
+  uses: HafslundEcoVannkraft/stratus-actions/hello-world@v1
+```
+
+### Using Specific Version
+
+Use the v1 tag for the first production release after a full history reset:
+
+```yaml
+- uses: HafslundEcoVannkraft/stratus-actions/hello-world@v1
+```
+
+## Contributing
+
+Contributions are welcome! Please feel free to submit a Pull Request.
+
+## License
+
+MIT
diff --git a/hello-world/action.yml b/hello-world/action.yml
new file mode 100644
index 0000000..b640662
--- /dev/null
+++ b/hello-world/action.yml
@@ -0,0 +1,8 @@
+name: "Hello world composite action"
+description: "A hello world composite action"
+runs:
+  using: "composite"
+  steps:
+    - name: Execute entrypoint script
+      shell: bash
+      run: ${{ github.action_path }}/entrypoint.sh
\ No newline at end of file
diff --git a/hello-world/entrypoint.sh b/hello-world/entrypoint.sh
new file mode 100755
index 0000000..5d24b0e
--- /dev/null
+++ b/hello-world/entrypoint.sh
@@ -0,0 +1,2 @@
+#!/bin/bash
+echo "Hello world from stratus-actions composite action"
\ No newline at end of file
diff --git a/release/README.md b/release/README.md
new file mode 100644
index 0000000..fa465e3
--- /dev/null
+++ b/release/README.md
@@ -0,0 +1,238 @@
+# Simple Version Bump and Release Action
+
+A lightweight composite GitHub Action (Bash + GitHub Script) that automates version bumping, tag creation, and release generation using GitHub's native release notes. No Docker or Node.js runtime required.
+
+## Features
+
+- üîÑ Automatic version bumping based on PR labels or commit messages
+- üè∑Ô∏è Git tag creation and management (including major version and "latest" tags)
+- üìù Native GitHub release notes generation (no external dependencies)
+- üéØ Simple and reliable
+- üìã Zero configuration required
+- ‚úÖ Works for both PR merges and direct pushes to main
+
+## How It Works
+
+1. **For Pull Requests**: Reads PR labels to determine version bump
+2. **For Push Events**: Parses the latest commit message on the branch for version keywords
+3. Creates a new semantic version tag (e.g., v1.2.3)
+4. Updates the major version tag (e.g., v1) to reference the latest release in that major version
+5. Updates the "latest" tag to always point to the most recent release
+6. Generates a GitHub release with native release notes
+
+## Version Bumping Rules
+
+### PR Labels (Priority)
+
+- `breaking-change` or `major` ‚Üí Major version (vX.0.0)
+- `enhancement`, `feature`, or `minor` ‚Üí Minor version (v0.X.0)
+- Any other labels or no labels ‚Üí Patch version (v0.0.X)
+
+### Commit Messages (Fallback)
+
+- `breaking change:` or `major:` ‚Üí Major version
+- `feat:` or `minor:` ‚Üí Minor version
+- `fix:` or `patch:` ‚Üí Patch version
+- Default ‚Üí Patch version
+
+## Usage
+
+### Basic Usage
+
+```yaml
+name: Release
+
+on:
+  push:
+    branches: [main]
+  pull_request:
+    types: [closed]
+    branches: [main]
+
+permissions:
+  contents: write
+  pull-requests: write
+
+jobs:
+  release:
+    if: github.event_name == 'push' || github.event.pull_request.merged == true
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+        with:
+          fetch-depth: 0
+
+      - name: Create Release
+        uses: HafslundEcoVannkraft/stratus-actions/release@v3
+```
+
+### With Options
+
+```yaml
+- name: Create Release
+  uses: HafslundEcoVannkraft/stratus-actions/release@v3
+  with:
+    draft: false # Create as published release (default: false)
+    prerelease: true # Mark as pre-release
+```
+
+## Inputs
+
+| Input        | Description             | Required | Default |
+| ------------ | ----------------------- | -------- | ------- |
+| `draft`      | Create release as draft | No       | `false` |
+| `prerelease` | Mark as pre-release     | No       | `false` |
+
+## Outputs
+
+| Output             | Description                | Example                                             |
+| ------------------ | -------------------------- | --------------------------------------------------- |
+| `new_version`      | Generated semantic version | `v1.2.3`                                            |
+| `previous_version` | Previous version           | `v1.2.2`                                            |
+| `bump_type`        | Version increment type     | `major`, `minor`, or `patch`                        |
+| `release_url`      | URL of created release     | `https://github.com/owner/repo/releases/tag/v1.2.3` |
+
+## Examples
+
+### Release on Merge to Main
+
+```yaml
+name: Release on Merge
+
+on:
+  pull_request:
+    types: [closed]
+    branches: [main]
+
+permissions:
+  contents: write
+  pull-requests: write
+
+jobs:
+  release:
+    if: github.event.pull_request.merged == true
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+        with:
+          fetch-depth: 0
+
+      - name: Create Release
+        uses: HafslundEcoVannkraft/stratus-actions/release@v3
+```
+
+### Release on Direct Push
+
+```yaml
+name: Release on Push
+
+on:
+  push:
+    branches: [main]
+
+permissions:
+  contents: write
+
+jobs:
+  release:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+        with:
+          fetch-depth: 0
+
+      - name: Create Release
+        uses: HafslundEcoVannkraft/stratus-actions/release@v3
+```
+
+### Draft Release for Review
+
+```yaml
+- name: Create Draft Release
+  uses: HafslundEcoVannkraft/stratus-actions/release@v3
+  with:
+    draft: true
+```
+
+## Release Notes
+
+This action uses GitHub's native release notes generation, which:
+
+- Automatically categorizes PRs based on labels
+- Lists contributors
+- Provides a full changelog
+- Can be configured via `.github/release.yml`
+
+To customize release notes categories, create `.github/release.yml`:
+
+```yaml
+changelog:
+  categories:
+    - title: üöÄ Features
+      labels:
+        - enhancement
+        - feature
+    - title: üêõ Bug Fixes
+      labels:
+        - bug
+        - bugfix
+```
+
+## Migration from v1
+
+The v2 release removes all AI-powered features and external dependencies:
+
+**Removed:**
+
+- Azure OpenAI integration
+- AI-generated release notes
+- Complex configuration options
+- External API dependencies
+
+**What stays the same:**
+
+- Version bumping logic
+- Tag creation
+- Basic release creation
+
+**What's new:**
+
+- Uses GitHub's native release notes
+- Zero configuration required
+- More reliable and faster
+- No API costs
+
+## Why Use This Action?
+
+- **Simple**: No complex configuration or external dependencies
+- **Reliable**: Uses only GitHub's native features
+- **Fast**: No external API calls
+- **Free**: No costs for AI or external services
+- **Maintainable**: Minimal code, easy to understand
+
+## Tag Management
+
+This action manages three levels of Git tags for your releases:
+
+1. **Specific version tags** (e.g., `v1.2.3`): Created for each release based on version bumping rules.
+2. **Major version tags** (e.g., `v1`): Automatically updated to point to the latest release within that major version.
+3. **Latest tag** (`latest`): Always points to the most recent release regardless of version.
+
+### Tag Usage Benefits
+
+- **Versioned dependencies**: Users can pin to specific versions (`v1.2.3`).
+- **Major version stability**: Users can reference major versions (`v1`) to get the latest updates without breaking changes.
+- **Latest releases**: Users can reference `latest` to always use the most current version.
+
+These tags are force-updated with each release to ensure they always point to the correct commit.
+
+## Troubleshooting & FAQ
+
+- **Q: Are the tags/releases created by this action "Verified"?**
+  - A: Yes, tags and releases created via the GitHub API or web UI are signed by GitHub and show as "Verified" in the commit history.
+- **Q: Can I use this action in a fork or mirror repo?**
+  - A: Yes, but ensure you have write permissions and the correct token setup for your use case.
+
+## License
+
+MIT
diff --git a/release/action.yml b/release/action.yml
new file mode 100644
index 0000000..ff76ca0
--- /dev/null
+++ b/release/action.yml
@@ -0,0 +1,207 @@
+name: "Simple Version Bump and Release"
+description: "Bumps version based on PR labels, creates tags, and generates GitHub releases with native release notes"
+
+inputs:
+  # Release Configuration
+  draft:
+    description: "Create release as draft"
+    required: false
+    default: "false"
+  prerelease:
+    description: "Mark as pre-release"
+    required: false
+    default: "false"
+  dry-run:
+    description: "If true, only calculate and output the next version, do not tag or release"
+    required: false
+    default: "false"
+
+outputs:
+  new_version:
+    description: "Generated semantic version number (e.g., v1.2.3)"
+    value: ${{ steps.version.outputs.new_version }}
+  previous_version:
+    description: "Previous version for comparison (e.g., v1.2.2)"
+    value: ${{ steps.version.outputs.previous_version }}
+  bump_type:
+    description: "Version increment type: major, minor, or patch"
+    value: ${{ steps.version.outputs.bump_type }}
+  release_url:
+    description: "URL of the created release"
+    value: ${{ steps.release.outputs.release_url }}
+
+runs:
+  using: "composite"
+  steps:
+    - name: Determine Version
+      id: version
+      shell: bash
+      env:
+        GH_TOKEN: ${{ github.token }}
+      run: |
+        set -e
+
+        # Get all tags and find the latest semantic version
+        echo "Fetching all tags to determine latest version..."
+        all_tags=$(git tag -l "v*")
+
+        # Initialize with default
+        latest_tag="v0.0.0"
+        latest_major=0
+        latest_minor=0
+        latest_patch=0
+
+        # Process all tags to find the latest semantic version
+        for tag in $all_tags; do
+          # Skip 'latest' tag
+          if [[ "$tag" == "latest" ]]; then
+            continue
+          fi
+
+          # Extract version components with validation
+          if [[ "$tag" =~ ^v([0-9]+)$ ]]; then
+            # Major version only (v1, v2, etc.)
+            tag_major="${BASH_REMATCH[1]}"
+            tag_minor=0
+            tag_patch=0
+          elif [[ "$tag" =~ ^v([0-9]+)\.([0-9]+)$ ]]; then
+            # Major.Minor version (v1.2, v2.0, etc.)
+            tag_major="${BASH_REMATCH[1]}"
+            tag_minor="${BASH_REMATCH[2]}"
+            tag_patch=0
+          elif [[ "$tag" =~ ^v([0-9]+)\.([0-9]+)\.([0-9]+).*$ ]]; then
+            # Full semantic version (v1.2.3, v2.0.1-beta, etc.)
+            tag_major="${BASH_REMATCH[1]}"
+            tag_minor="${BASH_REMATCH[2]}"
+            tag_patch="${BASH_REMATCH[3]}"
+          else
+            # Tag doesn't match expected format, skip it
+            echo "Skipping tag with non-semantic format: $tag"
+            continue
+          fi
+
+          # Compare versions and update if this one is newer
+          if [[ "$tag_major" -gt "$latest_major" ]] ||
+             [[ "$tag_major" -eq "$latest_major" && "$tag_minor" -gt "$latest_minor" ]] ||
+             [[ "$tag_major" -eq "$latest_major" && "$tag_minor" -eq "$latest_minor" && "$tag_patch" -gt "$latest_patch" ]]; then
+            latest_tag="$tag"
+            latest_major="$tag_major"
+            latest_minor="$tag_minor"
+            latest_patch="$tag_patch"
+          fi
+        done
+
+        echo "Latest semantic version tag: $latest_tag"
+
+        # Set variables for version calculation
+        major="$latest_major"
+        minor="$latest_minor"
+        patch="$latest_patch"
+
+        # Get PR labels for pull request events
+        if [[ "${{ github.event_name }}" == "pull_request" ]]; then
+          pr_labels="${{ join(github.event.pull_request.labels.*.name, ',') }}"
+          echo "PR labels: $pr_labels"
+        else
+          # For push events, check the commit message
+          commit_message=$(git log -1 --pretty=%B | tr '[:upper:]' '[:lower:]')
+          echo "Last commit message: $commit_message"
+          pr_labels=""
+        fi
+
+        # Determine version bump based on labels or commit message
+        bump_type=""
+
+        # Check PR labels first (for PR events)
+        if [[ -n "$pr_labels" ]]; then
+          if [[ "$pr_labels" == *"breaking-change"* ]] || [[ "$pr_labels" == *"major"* ]]; then
+            bump_type="major"
+          elif [[ "$pr_labels" == *"enhancement"* ]] || [[ "$pr_labels" == *"feature"* ]] || [[ "$pr_labels" == *"minor"* ]]; then
+            bump_type="minor"
+          else
+            bump_type="patch"
+          fi
+        else
+          # Fall back to commit message parsing (for push events)
+          if [[ "$commit_message" == *"breaking change:"* ]] || [[ "$commit_message" == *"major:"* ]]; then
+            bump_type="major"
+          elif [[ "$commit_message" == *"feat:"* ]] || [[ "$commit_message" == *"minor:"* ]]; then
+            bump_type="minor"
+          elif [[ "$commit_message" == *"fix:"* ]] || [[ "$commit_message" == *"patch:"* ]]; then
+            bump_type="patch"
+          else
+            bump_type="patch"  # Default to patch
+          fi
+        fi
+
+        # Calculate new version
+        if [[ "$bump_type" == "major" ]]; then
+          new_version="v$((major + 1)).0.0"
+        elif [[ "$bump_type" == "minor" ]]; then
+          new_version="v${major}.$((minor + 1)).0"
+        else
+          new_version="v${major}.${minor}.$((patch + 1))"
+        fi
+
+        echo "New version: $new_version (${bump_type} bump)"
+
+        # Output values
+        echo "new_version=$new_version" >> "$GITHUB_OUTPUT"
+        echo "previous_version=$latest_tag" >> "$GITHUB_OUTPUT"
+        echo "bump_type=$bump_type" >> "$GITHUB_OUTPUT"
+        echo "major=$major" >> "$GITHUB_OUTPUT"
+
+    - name: Create Tags
+      if: inputs.dry-run != 'true'
+      shell: bash
+      run: |
+        git config --global user.name "github-actions[bot]"
+        git config --global user.email "github-actions[bot]@users.noreply.github.com"
+
+        # Create a new tag for the new version
+        git tag -a "${{ steps.version.outputs.new_version }}" -m "Release ${{ steps.version.outputs.new_version }}"
+        git push origin "${{ steps.version.outputs.new_version }}"
+
+        # Force update the major version tag to point to the current commit
+        if [[ "${{ steps.version.outputs.major }}" -gt 0 ]]; then
+          # Extract the major version from the new version (more reliably)
+          new_major=$(echo "${{ steps.version.outputs.new_version }}" | sed 's/^v//' | cut -d. -f1)
+
+          # Create or update the major version tag
+          git tag -f "v${new_major}"
+          git push origin "v${new_major}" --force
+        fi
+
+        # Create or update the 'latest' tag to always point to the most recent release
+        git tag -f "latest"
+        git push origin "latest" --force
+
+    - name: Create Release
+      if: inputs.dry-run != 'true'
+      id: release
+      uses: actions/github-script@v7
+      with:
+        script: |
+          const { data: release } = await github.rest.repos.createRelease({
+            owner: context.repo.owner,
+            repo: context.repo.repo,
+            tag_name: '${{ steps.version.outputs.new_version }}',
+            name: '${{ steps.version.outputs.new_version }}',
+            draft: ${{ inputs.draft }},
+            prerelease: ${{ inputs.prerelease }},
+            target_commitish: context.sha,
+            generate_release_notes: true  // Use GitHub's native release notes
+          });
+
+          console.log(`Created release: ${release.html_url}`);
+          core.setOutput('release_url', release.html_url);
+
+          // Comment on PR if this is a PR event
+          if (context.eventName === 'pull_request' && context.payload.pull_request) {
+            await github.rest.issues.createComment({
+              owner: context.repo.owner,
+              repo: context.repo.repo,
+              issue_number: context.payload.pull_request.number,
+              body: `üöÄ Released version ${{ steps.version.outputs.new_version }}!\n\nView the release: ${release.html_url}`
+            });
+          }
